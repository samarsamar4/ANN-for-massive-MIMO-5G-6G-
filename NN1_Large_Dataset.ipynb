{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#191970; font-size:38px\">MIMO-NN1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Tools</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#FF5733 ; font-size:15px\"> CommPy</h1> is an open source toolkit implementing digital communications algorithms in Python using NumPy and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-commpy in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from scikit-commpy) (3.2.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from scikit-commpy) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from scikit-commpy) (1.18.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from matplotlib->scikit-commpy) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from matplotlib->scikit-commpy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from matplotlib->scikit-commpy) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from matplotlib->scikit-commpy) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from cycler>=0.10->matplotlib->scikit-commpy) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-commpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "from numpy import *\n",
    "from numpy.linalg import inv\n",
    "from commpy.utilities import *\n",
    "from commpy.modulation import QAMModem\n",
    "from commpy.channels import *\n",
    "from commpy.links import *\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Functions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. High Power Amplifier Output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpa_sspa_modif_rapp(vin,Vsat,p,q,G,A,B):\n",
    "    A=-345\n",
    "    a0=abs(vin)\n",
    "    theta=np.angle(vin)\n",
    "    Am=(G*a0)/((1+(G*a0/Vsat)**(2*p))**(1/(2*p)))\n",
    "    Bm=(A*(a0**q))/((1+(a0/B)**(q)))\n",
    "    vout=Am*np.exp(1j*(theta+Bm))\n",
    "    return(vout)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Non Linear Distortion Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_K0_sigma2_d(vin,vout):\n",
    "    K0 = np.mean(vout*np.conj(vin))/np.mean(np.absolute(vin)**2)\n",
    "    sigma2_d = np.var(vout - K0*vin)\n",
    "    return(K0,sigma2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Basic PA Non linear Distortion Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12.804034357960463-0.44343761084051253j)\n",
      "0.013572902343040375\n"
     ]
    }
   ],
   "source": [
    "IBO=1\n",
    "p=1.1\n",
    "q=4\n",
    "Vsat=1.9\n",
    "G=16\n",
    "A=-345\n",
    "B=0.17\n",
    "val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "coeff_IBO_m1dB=val_IBO_m1dB*np.sqrt(10**(-IBO/10))\n",
    "s=np.random.randn(1,1000000)\n",
    "vin1 = np.sqrt(1/2)*(s+1j*s)\n",
    "vin01 = coeff_IBO_m1dB*vin1\n",
    "a0=np.absolute(vin01)\n",
    "a02=a0**2  \n",
    "theta=np.angle(vin01)\n",
    "Am=(G*a0)/((1+(G*a0/Vsat)**(2*p))**(1/(2*p)))\n",
    "Bm=(A*(a0**q))/((1+(a0/B)**(q)))\n",
    "Sm=Am*np.exp(1j*(Bm))\n",
    "vout1=Am*np.exp(1j*(theta+Bm))\n",
    "K0 = np.mean(vout1*np.conj(vin01))/np.mean(np.absolute(vin01)**2)\n",
    "sigma2_d = np.var(vout1 - K0*vin01) \n",
    "print(K0)\n",
    "print(sigma2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Training Dataset </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 1000 H; \n",
    "For each H, we have 5000 S (input of NN1) and 5000 X_gd (output of NN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Mr=10\n",
    "Mt=100\n",
    "M=16\n",
    "SNRdb=600\n",
    "N_bits=Mr*np.log2(M)\n",
    "MSE=np.zeros((Mt,50))\n",
    "x_gd_amp0=np.zeros((Mt,1))\n",
    "y_gd_r0=np.zeros([Mt,100])\n",
    "PAPR_GD=np.zeros((Mt,1))\n",
    "MUIgdi= np.zeros((Mt,1))\n",
    "SERgdi=np.zeros((Mt,1))\n",
    "BERgdi=np.zeros((Mt,1))\n",
    "GD_Execution_time=0\n",
    "HH=np.zeros((1,2000))\n",
    "S=np.zeros((400000,20))\n",
    "ZZ=np.zeros((400000,10),dtype=complex)\n",
    "Niter=50\n",
    "mu1=0.0022\n",
    "lamda=0.00071\n",
    "mu2=1\n",
    "eps=1e-2\n",
    "x_gd=np.zeros([Mt,1])\n",
    "X_gd=np.zeros((400000,100))\n",
    "gdx1=np.zeros([Mt,Niter])\n",
    "d=np.zeros([Mt,1])\n",
    "X=np.zeros((400000,200))\n",
    "H=(1/np.sqrt(2*Mt))*(np.random.randn(Mr,Mt)+1j*np.random.randn(Mr,Mt))\n",
    "HR=H.flatten()\n",
    "realh=np.real(HR)\n",
    "imagh=np.imag(HR)\n",
    "Hr=np.concatenate((realh,imagh),axis=0).reshape(-1,1)\n",
    "Hr=np.reshape(Hr, (2000, 1)).T\n",
    "HH=Hr\n",
    "for j in range(400000):\n",
    "    bits = np.random.randint(2, size=int(N_bits))\n",
    "    QAM16 = QAMModem(16)\n",
    "    z=QAM16.modulate(bits)\n",
    "    Z = np.reshape(z, (1, 10)).T\n",
    "    ZZ[j]=Z.T\n",
    "    reals=np.real(Z.T)\n",
    "    imags=np.imag(Z.T)\n",
    "    s=np.concatenate((reals,imags),axis=1)\n",
    "    S[j]=s\n",
    "    ## CDm algo\n",
    "    for i in range(Niter):\n",
    "        gdx1=2*np.conj(K0*np.transpose(H)).dot(K0*H.dot(x_gd)+H.dot(d)-Z)\n",
    "        x_gd=x_gd-mu1*gdx1\n",
    "        realx=np.real( x_gd)\n",
    "        imagx=np.imag( x_gd)\n",
    "        x_z=np.concatenate((realx,imagx),axis=0).T\n",
    "        X[j]=x_z\n",
    "        ## HPA \n",
    "        val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "        coeff_IBO_m1dB=val_IBO_m1dB*np.sqrt((1/np.var(x_gd)))*np.sqrt(10**(-IBO/10))\n",
    "        vin2=coeff_IBO_m1dB*x_gd\n",
    "        vout2=hpa_sspa_modif_rapp(vin2,Vsat,p,q,G,A,B)\n",
    "        K0,sigma2_d=find_K0_sigma2_d (vin2,vout2)\n",
    "        d=vout2-K0*vin2\n",
    "        y_gd =np.array(vout2/coeff_IBO_m1dB)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Data Normalization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=S[:350000,:]\n",
    "y_train=X[:350000,:]\n",
    "\n",
    "X_test=S[350000:,:]\n",
    "y_test=X[350000:,:] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Artifical Neural Network</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNMSE(y_true,y_pred_test):\n",
    "    NMSE=np.zeros([1000,1])\n",
    "    recievehh=np.zeros([1000,10],dtype=complex)\n",
    "    Y_gdr=y_pred_test[:,:100]\n",
    "    Y_gdi=y_pred_test[:,100:]\n",
    "    Y_gd=Y_gdr+1j*Y_gdi\n",
    "    Shr=X_test[:,:10]\n",
    "    Shi=X_test[:,10:20]\n",
    "    SSh=Shr+1j*Shi\n",
    "    for i in range(1000):\n",
    "        val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "        coeff_IBO_m1dB=val_IBO_m1dB*np.sqrt((1/np.var(Y_gd[i])))*np.sqrt(10**(-IBO/10))\n",
    "        vin2=coeff_IBO_m1dB*Y_gd[i]\n",
    "        vout2=hpa_sspa_modif_rapp(vin2,Vsat,p,q,G,A,B)\n",
    "        Y_gd_amp = vout2/coeff_IBO_m1dB\n",
    "        recieveh=(H.dot(Y_gd_amp)).reshape((10))\n",
    "        recievehh[i]=recieveh\n",
    "        NMSE[i]=(np.mean(np.abs(SSh[i]-recieveh)**2)/np.mean(np.abs(SSh[i])**2))\n",
    "        NMSEdb=10*np.log10(np.mean(NMSE))\n",
    "    #recievehhh=recievehh.flatten()\n",
    "    #realr=np.real(recievehhh)\n",
    "    #imagr=np.imag(recievehhh)\n",
    "    #plt.scatter(realr,imagr) \n",
    "    return NMSEdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "def Mean(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "def log10(x):\n",
    "    numerator = tf.math.log(x)\n",
    "    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "def NMSE(y_true, y_pred):\n",
    "    NMS=K.zeros(shape=(1000))\n",
    "    NMSEdb=K.zeros(shape=(1000))\n",
    "    #recieveh=K.zeros([1000,10])\n",
    "    y_predt=tf.convert_to_tensor(y_pred,dtype=tf.float32)\n",
    "    Y_gdr=y_predt[:1000,:100]\n",
    "    Y_gdi=y_predt[:1000,100:]\n",
    "    Y_gd=tf.complex(Y_gdr,Y_gdi)\n",
    "    X_testt=tf.convert_to_tensor(X_train,dtype=tf.float32)\n",
    "    Shr=X_testt[:1000,:10]\n",
    "    Shi=X_testt[:1000,10:20]\n",
    "    SSh=tf.complex(Shr,Shi)\n",
    "    NMSE=[]\n",
    "    for i in range(1000):\n",
    "        val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "        coeff_IBO_m1dB=val_IBO_m1dB*tf.math.sqrt((1/K.var(Y_gd[i])))*np.sqrt(10**(-IBO/10))\n",
    "        vin2=coeff_IBO_m1dB*Y_gd[i]\n",
    "        A=-345\n",
    "        a0=K.abs(vin2)\n",
    "        theta=tf.math.angle(vin2)\n",
    "        Am=(G*a0)/((1+(G*a0/Vsat)**(2*p))**(1/(2*p)))\n",
    "        Bm=(A*(a0**q))/((1+(a0/B)**(q)))\n",
    "        vout2=tf.complex(Am,0.0)*tf.math.exp(tf.complex(0.0,theta+Bm))\n",
    "        Y_gd_amp = vout2/coeff_IBO_m1dB\n",
    "        Y_gd_amp0=K.reshape(Y_gd_amp,(100,1))\n",
    "        HH=K.constant(H,dtype=complex64)\n",
    "        recieveh=K.dot(HH,(Y_gd_amp0))\n",
    "        recievehh=K.reshape(recieveh,(1,10))\n",
    "        NMS=K.mean(K.abs(tf.math.subtract(recievehh,SSh[i])**2))/K.mean(K.abs(SSh[i])**2)\n",
    "        #NMSE.append(NMS)\n",
    "        #NMSEdb=10*log10(Mean(NMSE))\n",
    "        NMSEdb=10*log10(K.mean(NMS))\n",
    "    return NMSEdb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350000 samples, validate on 50000 samples\n",
      "Epoch 1/4000\n",
      "350000/350000 [==============================] - 8s 24us/step - loss: 0.0435 - mae: 0.0344 - NMSE: 2.4753 - val_loss: 0.0211 - val_mae: 0.0168 - val_NMSE: 3.4546\n",
      "Epoch 2/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0167 - mae: 0.0132 - NMSE: 2.8229 - val_loss: 0.0132 - val_mae: 0.0105 - val_NMSE: 3.8862\n",
      "Epoch 3/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0114 - mae: 0.0090 - NMSE: 3.0957 - val_loss: 0.0100 - val_mae: 0.0079 - val_NMSE: 4.0421\n",
      "Epoch 4/4000\n",
      "350000/350000 [==============================] - 3s 9us/step - loss: 0.0093 - mae: 0.0074 - NMSE: 3.0232 - val_loss: 0.0087 - val_mae: 0.0069 - val_NMSE: 4.0658\n",
      "Epoch 5/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0084 - mae: 0.0067 - NMSE: 3.6352 - val_loss: 0.0081 - val_mae: 0.0064 - val_NMSE: 4.0938\n",
      "Epoch 6/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0079 - mae: 0.0063 - NMSE: 3.4709 - val_loss: 0.0077 - val_mae: 0.0062 - val_NMSE: 4.0964\n",
      "Epoch 7/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0076 - mae: 0.0061 - NMSE: 3.2891 - val_loss: 0.0075 - val_mae: 0.0060 - val_NMSE: 4.1017\n",
      "Epoch 8/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0074 - mae: 0.0059 - NMSE: 3.3028 - val_loss: 0.0072 - val_mae: 0.0058 - val_NMSE: 4.0943\n",
      "Epoch 9/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0072 - mae: 0.0057 - NMSE: 3.5464 - val_loss: 0.0071 - val_mae: 0.0056 - val_NMSE: 4.0962\n",
      "Epoch 10/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0070 - mae: 0.0056 - NMSE: 3.5084 - val_loss: 0.0069 - val_mae: 0.0055 - val_NMSE: 4.0830\n",
      "Epoch 11/4000\n",
      "350000/350000 [==============================] - 3s 9us/step - loss: 0.0068 - mae: 0.0055 - NMSE: 3.6369 - val_loss: 0.0067 - val_mae: 0.0054 - val_NMSE: 4.0862\n",
      "Epoch 12/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0067 - mae: 0.0053 - NMSE: 3.2645 - val_loss: 0.0066 - val_mae: 0.0053 - val_NMSE: 4.0902\n",
      "Epoch 13/4000\n",
      "350000/350000 [==============================] - 4s 10us/step - loss: 0.0065 - mae: 0.0052 - NMSE: 3.6358 - val_loss: 0.0065 - val_mae: 0.0052 - val_NMSE: 4.0997\n",
      "Epoch 14/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0064 - mae: 0.0051 - NMSE: 3.3934 - val_loss: 0.0063 - val_mae: 0.0051 - val_NMSE: 4.1002\n",
      "Epoch 15/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0063 - mae: 0.0050 - NMSE: 3.3130 - val_loss: 0.0062 - val_mae: 0.0050 - val_NMSE: 4.0970\n",
      "Epoch 16/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0062 - mae: 0.0049 - NMSE: 3.6432 - val_loss: 0.0061 - val_mae: 0.0049 - val_NMSE: 4.0984\n",
      "Epoch 17/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0061 - mae: 0.0049 - NMSE: 3.6008 - val_loss: 0.0060 - val_mae: 0.0048 - val_NMSE: 4.1087\n",
      "Epoch 18/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0060 - mae: 0.0048 - NMSE: 3.7504 - val_loss: 0.0059 - val_mae: 0.0047 - val_NMSE: 4.0944\n",
      "Epoch 19/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0059 - mae: 0.0047 - NMSE: 3.6407 - val_loss: 0.0058 - val_mae: 0.0046 - val_NMSE: 4.0982\n",
      "Epoch 20/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0058 - mae: 0.0046 - NMSE: 3.1652 - val_loss: 0.0057 - val_mae: 0.0046 - val_NMSE: 4.1031\n",
      "Epoch 21/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0057 - mae: 0.0045 - NMSE: 3.6084 - val_loss: 0.0056 - val_mae: 0.0045 - val_NMSE: 4.1102\n",
      "Epoch 22/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0056 - mae: 0.0045 - NMSE: 3.5732 - val_loss: 0.0055 - val_mae: 0.0044 - val_NMSE: 4.1111\n",
      "Epoch 23/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0055 - mae: 0.0044 - NMSE: 3.3458 - val_loss: 0.0054 - val_mae: 0.0043 - val_NMSE: 4.1182\n",
      "Epoch 24/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0054 - mae: 0.0043 - NMSE: 3.2845 - val_loss: 0.0054 - val_mae: 0.0043 - val_NMSE: 4.1256\n",
      "Epoch 25/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0053 - mae: 0.0042 - NMSE: 3.5678 - val_loss: 0.0053 - val_mae: 0.0042 - val_NMSE: 4.1343\n",
      "Epoch 26/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0052 - mae: 0.0042 - NMSE: 3.4005 - val_loss: 0.0052 - val_mae: 0.0041 - val_NMSE: 4.1362\n",
      "Epoch 27/4000\n",
      "350000/350000 [==============================] - 3s 10us/step - loss: 0.0052 - mae: 0.0041 - NMSE: 3.2596 - val_loss: 0.0051 - val_mae: 0.0041 - val_NMSE: 4.1368\n",
      "Epoch 28/4000\n",
      "130000/350000 [==========>...................] - ETA: 1s - loss: 0.0051 - mae: 0.0041 - NMSE: 3.07"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Activation, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "model = Sequential()\n",
    "#keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.1, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "model.add(Dense(units =200, kernel_initializer = 'uniform', activation = 'relu', input_dim =20))\n",
    "model.add(Dense(units =200, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model.compile(optimizer = 'Adamax', loss = root_mean_squared_error, metrics = ['mae',NMSE])\n",
    "history =model.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size=10000, epochs=4000, shuffle=True)\n",
    "y_pred= model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <h1 style=\"color:#006400\"> Weights Vector of NN1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88600\n"
     ]
    }
   ],
   "source": [
    "first_layer_weights =model.layers[0].get_weights()[0] \n",
    "first=first_layer_weights.flatten()\n",
    "first_layer_biases  = model.layers[0].get_weights()[1]\n",
    "first_layer=np.concatenate((first,first_layer_biases),axis=0)\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "second=second_layer_weights.flatten()\n",
    "second_layer_biases  = model.layers[1].get_weights()[1]\n",
    "second_layer=np.concatenate((second,second_layer_biases),axis=0)\n",
    "weights=np.concatenate((first_layer,second_layer),axis=0)\n",
    "print (len(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Make Predictions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred= model.predict(X_train)\n",
    "#y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Accuracy Representation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.grid(True,which=\"both\", linestyle='--')\n",
    "plt.ylabel('Accuracy') \n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Loss Representation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-ef952d05c836>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwhich\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"both\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.grid(True,which=\"both\", linestyle='--')\n",
    "plt.ylabel('Loss') \n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Mean-Squared-Error</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squred Error: -28.941871041108605\n"
     ]
    }
   ],
   "source": [
    "NMSE=np.zeros([1000,1])\n",
    "recievehh=np.zeros([1000,10],dtype=complex)\n",
    "Y_gdr=y_pred_test[:,:100]\n",
    "Y_gdi=1j*y_pred_test[:,100:]\n",
    "Y_gd=Y_gdr+Y_gdi\n",
    "Shr=X_test[:,:10]\n",
    "Shi=1j*X_test[:,10:20]\n",
    "SSh=Shr+Shi\n",
    "for i in range(1000):\n",
    "    val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "    coeff_IBO_m1dB=val_IBO_m1dB*np.sqrt((1/np.var(Y_gd[i])))*np.sqrt(10**(-IBO/10))\n",
    "    vin2=coeff_IBO_m1dB*Y_gd[i]\n",
    "    vout2=hpa_sspa_modif_rapp(vin2,Vsat,p,q,G,A,B)\n",
    "    Y_gd_amp = vout2/coeff_IBO_m1dB\n",
    "    recieveh=(H.dot(Y_gd_amp)).reshape((10))\n",
    "    recievehh[i]=recieveh\n",
    "    NMSE[i]=(np.mean(np.abs(SSh[i]-recieveh)**2)/np.mean(np.abs(SSh[i])**2))\n",
    "    NMSEdb=10*np.log10(np.mean(NMSE))\n",
    "#recievehhh=recievehh.flatten()\n",
    "#realr=np.real(recievehhh)\n",
    "#imagr=np.imag(recievehhh)\n",
    "#plt.scatter(realr,imagr) \n",
    "print('Mean Squred Error:', NMSEdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-9443a29b53b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "print(NMSE(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-c566ba9d0cc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "print(NMSE(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuenv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
