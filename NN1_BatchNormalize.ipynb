{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#191970; font-size:38px\">MIMO-NN1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Tools</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#FF5733 ; font-size:15px\"> CommPy</h1> is an open source toolkit implementing digital communications algorithms in Python using NumPy and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-commpy in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (0.5.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from scikit-commpy) (3.2.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from scikit-commpy) (1.18.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from scikit-commpy) (1.4.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from matplotlib->scikit-commpy) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from matplotlib->scikit-commpy) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from matplotlib->scikit-commpy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from matplotlib->scikit-commpy) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\gpuenv\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->scikit-commpy) (1.14.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-commpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "from numpy import *\n",
    "from numpy.linalg import inv\n",
    "from commpy.utilities import *\n",
    "from commpy.modulation import QAMModem\n",
    "from commpy.channels import *\n",
    "from commpy.links import *\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Functions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. High Power Amplifier Output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpa_sspa_modif_rapp(vin,Vsat,p,q,G,A,B):\n",
    "    A=-345\n",
    "    a0=abs(vin)\n",
    "    theta=np.angle(vin)\n",
    "    Am=(G*a0)/((1+(G*a0/Vsat)**(2*p))**(1/(2*p)))\n",
    "    Bm=(A*(a0**q))/((1+(a0/B)**(q)))\n",
    "    vout=Am*np.exp(1j*(theta+Bm))\n",
    "    return(vout)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Non Linear Distortion Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_K0_sigma2_d(vin,vout):\n",
    "    K0 = np.mean(vout*np.conj(vin))/np.mean(np.absolute(vin)**2)\n",
    "    sigma2_d = np.var(vout - K0*vin)\n",
    "    return(K0,sigma2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Basic PA Non linear Distortion Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13.724529890387597-0.24702540545627025j)\n",
      "0.005273746255996075\n"
     ]
    }
   ],
   "source": [
    "IBO=3\n",
    "p=1.1\n",
    "q=4\n",
    "Vsat=1.9\n",
    "G=16\n",
    "A=-345\n",
    "B=0.17\n",
    "val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "coeff_IBO_m1dB=val_IBO_m1dB*np.sqrt(10**(-IBO/10))\n",
    "s=np.random.randn(1,1000000)\n",
    "vin1 = np.sqrt(1/2)*(s+1j*s)\n",
    "vin01 = coeff_IBO_m1dB*vin1\n",
    "a0=np.absolute(vin01)\n",
    "a02=a0**2  \n",
    "theta=np.angle(vin01)\n",
    "Am=(G*a0)/((1+(G*a0/Vsat)**(2*p))**(1/(2*p)))\n",
    "Bm=(A*(a0**q))/((1+(a0/B)**(q)))\n",
    "Sm=Am*np.exp(1j*(Bm))\n",
    "vout1=Am*np.exp(1j*(theta+Bm))\n",
    "K0 = np.mean(vout1*np.conj(vin01))/np.mean(np.absolute(vin01)**2)\n",
    "sigma2_d = np.var(vout1 - K0*vin01) \n",
    "print(K0)\n",
    "print(sigma2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\">Training Dataset </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 1000 H; \n",
    "For each H, we have 5000 S (input of NN1) and 5000 X_gd (output of NN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01708238 -0.02058135 -0.1248105  ...  0.1196112  -0.02955268\n",
      "   0.06262674]\n",
      " [-0.07426327 -0.00488895  0.05883009 ...  0.00682864  0.04032701\n",
      "  -0.04656127]\n",
      " [ 0.04879092  0.00309107 -0.04091963 ...  0.03135259 -0.02896807\n",
      "  -0.01459549]\n",
      " ...\n",
      " [ 0.02238798  0.03238247  0.02563201 ...  0.09846181  0.07374631\n",
      "  -0.04586184]\n",
      " [-0.04619295 -0.01814719 -0.05585953 ...  0.00014527  0.02901694\n",
      "   0.02103972]\n",
      " [-0.08611232 -0.0308179   0.0156656  ...  0.03885533 -0.06267606\n",
      "   0.03491109]]\n"
     ]
    }
   ],
   "source": [
    "Mr=10\n",
    "Mt=100\n",
    "M=16\n",
    "SNRdb=600\n",
    "N_bits=Mr*np.log2(M)\n",
    "MSE=np.zeros((Mt,50))\n",
    "x_gd_amp0=np.zeros((Mt,1))\n",
    "y_gd_r0=np.zeros([Mt,100])\n",
    "PAPR_GD=np.zeros((Mt,1))\n",
    "MUIgdi= np.zeros((Mt,1))\n",
    "SERgdi=np.zeros((Mt,1))\n",
    "BERgdi=np.zeros((Mt,1))\n",
    "GD_Execution_time=0\n",
    "HH=np.zeros((1,2000))\n",
    "S=np.zeros((11000,20))\n",
    "ZZ=np.zeros((11000,10),dtype=complex)\n",
    "Niter=50\n",
    "mu1=0.0017\n",
    "lamda=0.00071\n",
    "mu2=1\n",
    "eps=1e-2\n",
    "x_gd=np.zeros([Mt,1])\n",
    "X_gd=np.zeros((11000,100))\n",
    "gdx1=np.zeros([Mt,Niter])\n",
    "d=np.zeros([Mt,1])\n",
    "X=np.zeros((11000,200))\n",
    "H=(1/np.sqrt(2*Mt))*(np.random.randn(Mr,Mt)+1j*np.random.randn(Mr,Mt))\n",
    "HR=H.flatten()\n",
    "realh=np.real(HR)\n",
    "imagh=np.imag(HR)\n",
    "Hr=np.concatenate((realh,imagh),axis=0).reshape(-1,1)\n",
    "Hr=np.reshape(Hr, (2000, 1)).T\n",
    "HH=Hr\n",
    "for j in range(11000):\n",
    "    bits = np.random.randint(2, size=int(N_bits))\n",
    "    QAM16 = QAMModem(16)\n",
    "    z=QAM16.modulate(bits)\n",
    "    Z = np.reshape(z, (1, 10)).T\n",
    "    ZZ[j]=Z.T\n",
    "    reals=np.real(Z.T)\n",
    "    imags=np.imag(Z.T)\n",
    "    s=np.concatenate((reals,imags),axis=1)\n",
    "    S[j]=s\n",
    "    ## CDm algo\n",
    "    for i in range(Niter):\n",
    "        gdx1=2*np.conj(K0*np.transpose(H)).dot(K0*H.dot(x_gd)+H.dot(d)-Z)\n",
    "        x_gd=x_gd-mu1*gdx1\n",
    "        realx=np.real( x_gd)\n",
    "        imagx=np.imag( x_gd)\n",
    "        x_z=np.concatenate((realx,imagx),axis=0).T\n",
    "        X[j]=x_z\n",
    "        ## HPA \n",
    "        val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "        coeff_IBO_m1dB=val_IBO_m1dB*np.sqrt((1/np.var(x_gd)))*np.sqrt(10**(-IBO/10))\n",
    "        vin2=coeff_IBO_m1dB*x_gd\n",
    "        vout2=hpa_sspa_modif_rapp(vin2,Vsat,p,q,G,A,B)\n",
    "        K0,sigma2_d=find_K0_sigma2_d (vin2,vout2)\n",
    "        d=vout2-K0*vin2\n",
    "        y_gd =np.array(vout2/coeff_IBO_m1dB)\n",
    "print(X)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Data Normalization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=S[:8000,:]\n",
    "y_train=X[:8000,:]\n",
    "\n",
    "X_test=S[8000:,:]\n",
    "y_test=X[8000:,:] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Artifical Neural Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here owr neural network NN1 for each H\n",
    "<h1 style=\"color:#191970; font-size:14px\">Input:</h1> 1000 S\n",
    "<h1 style=\"color:#191970; font-size:14px\">Output:</h1>1000 X_gd\n",
    "<h1 style=\"color:#191970; font-size:14px\">The activation function selu 'Scaled Exponential Linear' is used for Self-Normalizing Neural Networks </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/500\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.0041 - accuracy: 0.0069 - val_loss: 0.0030 - val_accuracy: 0.0160\n",
      "Epoch 2/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0027 - accuracy: 0.0223 - val_loss: 0.0023 - val_accuracy: 0.0370\n",
      "Epoch 3/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 0.0022 - accuracy: 0.0496 - val_loss: 0.0019 - val_accuracy: 0.0707\n",
      "Epoch 4/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0019 - accuracy: 0.0839 - val_loss: 0.0017 - val_accuracy: 0.0920\n",
      "Epoch 5/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0016 - accuracy: 0.1098 - val_loss: 0.0015 - val_accuracy: 0.1193\n",
      "Epoch 6/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0015 - accuracy: 0.1354 - val_loss: 0.0013 - val_accuracy: 0.1513\n",
      "Epoch 7/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.0013 - accuracy: 0.1620 - val_loss: 0.0012 - val_accuracy: 0.1807\n",
      "Epoch 8/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0012 - accuracy: 0.1912 - val_loss: 0.0011 - val_accuracy: 0.2060\n",
      "Epoch 9/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0011 - accuracy: 0.2205 - val_loss: 9.8724e-04 - val_accuracy: 0.2327\n",
      "Epoch 10/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 9.5638e-04 - accuracy: 0.2474 - val_loss: 8.9455e-04 - val_accuracy: 0.2563\n",
      "Epoch 11/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 8.6709e-04 - accuracy: 0.2720 - val_loss: 8.1240e-04 - val_accuracy: 0.2763\n",
      "Epoch 12/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 7.8800e-04 - accuracy: 0.2993 - val_loss: 7.3977e-04 - val_accuracy: 0.3077\n",
      "Epoch 13/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 7.1816e-04 - accuracy: 0.3282 - val_loss: 6.7563e-04 - val_accuracy: 0.3293\n",
      "Epoch 14/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 6.5637e-04 - accuracy: 0.3566 - val_loss: 6.1902e-04 - val_accuracy: 0.3517\n",
      "Epoch 15/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 6.0190e-04 - accuracy: 0.3812 - val_loss: 5.6878e-04 - val_accuracy: 0.3740\n",
      "Epoch 16/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.5362e-04 - accuracy: 0.4030 - val_loss: 5.2397e-04 - val_accuracy: 0.3923\n",
      "Epoch 17/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1024e-04 - accuracy: 0.4244 - val_loss: 4.8385e-04 - val_accuracy: 0.4200\n",
      "Epoch 18/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 4.7153e-04 - accuracy: 0.4433 - val_loss: 4.4778e-04 - val_accuracy: 0.4407\n",
      "Epoch 19/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 4.3663e-04 - accuracy: 0.4666 - val_loss: 4.1531e-04 - val_accuracy: 0.4667\n",
      "Epoch 20/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 4.0518e-04 - accuracy: 0.4855 - val_loss: 3.8610e-04 - val_accuracy: 0.4867\n",
      "Epoch 21/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 3.7685e-04 - accuracy: 0.5041 - val_loss: 3.5978e-04 - val_accuracy: 0.5063\n",
      "Epoch 22/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 3.5130e-04 - accuracy: 0.5224 - val_loss: 3.3601e-04 - val_accuracy: 0.5263\n",
      "Epoch 23/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 3.2819e-04 - accuracy: 0.5384 - val_loss: 3.1449e-04 - val_accuracy: 0.5420\n",
      "Epoch 24/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 3.0723e-04 - accuracy: 0.5537 - val_loss: 2.9499e-04 - val_accuracy: 0.5547\n",
      "Epoch 25/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 2.8822e-04 - accuracy: 0.5652 - val_loss: 2.7731e-04 - val_accuracy: 0.5690\n",
      "Epoch 26/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 2.7110e-04 - accuracy: 0.5816 - val_loss: 2.6124e-04 - val_accuracy: 0.5893\n",
      "Epoch 27/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 2.5543e-04 - accuracy: 0.5956 - val_loss: 2.4669e-04 - val_accuracy: 0.6040\n",
      "Epoch 28/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 2.4133e-04 - accuracy: 0.6070 - val_loss: 2.3353e-04 - val_accuracy: 0.6197\n",
      "Epoch 29/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 2.2856e-04 - accuracy: 0.6206 - val_loss: 2.2168e-04 - val_accuracy: 0.6270\n",
      "Epoch 30/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 2.1715e-04 - accuracy: 0.6325 - val_loss: 2.1103e-04 - val_accuracy: 0.6377\n",
      "Epoch 31/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 2.0680e-04 - accuracy: 0.6416 - val_loss: 2.0147e-04 - val_accuracy: 0.6493\n",
      "Epoch 32/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 1.9766e-04 - accuracy: 0.6515 - val_loss: 1.9289e-04 - val_accuracy: 0.6603\n",
      "Epoch 33/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.8939e-04 - accuracy: 0.6643 - val_loss: 1.8522e-04 - val_accuracy: 0.6717\n",
      "Epoch 34/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.8201e-04 - accuracy: 0.6729 - val_loss: 1.7839e-04 - val_accuracy: 0.6777\n",
      "Epoch 35/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 1.7543e-04 - accuracy: 0.6805 - val_loss: 1.7226e-04 - val_accuracy: 0.6860\n",
      "Epoch 36/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.6954e-04 - accuracy: 0.6891 - val_loss: 1.6670e-04 - val_accuracy: 0.6940\n",
      "Epoch 37/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 1.6418e-04 - accuracy: 0.6956 - val_loss: 1.6170e-04 - val_accuracy: 0.7040\n",
      "Epoch 38/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 1.5936e-04 - accuracy: 0.7020 - val_loss: 1.5712e-04 - val_accuracy: 0.7087\n",
      "Epoch 39/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 1.5495e-04 - accuracy: 0.7080 - val_loss: 1.5290e-04 - val_accuracy: 0.7130\n",
      "Epoch 40/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 1.5083e-04 - accuracy: 0.7150 - val_loss: 1.4898e-04 - val_accuracy: 0.7213\n",
      "Epoch 41/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 1.4702e-04 - accuracy: 0.7200 - val_loss: 1.4529e-04 - val_accuracy: 0.7260\n",
      "Epoch 42/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 1.4338e-04 - accuracy: 0.7294 - val_loss: 1.4177e-04 - val_accuracy: 0.7330\n",
      "Epoch 43/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.3992e-04 - accuracy: 0.7355 - val_loss: 1.3834e-04 - val_accuracy: 0.7403\n",
      "Epoch 44/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.3651e-04 - accuracy: 0.7427 - val_loss: 1.3498e-04 - val_accuracy: 0.7437\n",
      "Epoch 45/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.3322e-04 - accuracy: 0.7487 - val_loss: 1.3164e-04 - val_accuracy: 0.7480\n",
      "Epoch 46/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 1.2989e-04 - accuracy: 0.7546 - val_loss: 1.2829e-04 - val_accuracy: 0.7537\n",
      "Epoch 47/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.2651e-04 - accuracy: 0.7600 - val_loss: 1.2492e-04 - val_accuracy: 0.7613\n",
      "Epoch 48/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.2312e-04 - accuracy: 0.7653 - val_loss: 1.2150e-04 - val_accuracy: 0.7680\n",
      "Epoch 49/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 1.1971e-04 - accuracy: 0.7704 - val_loss: 1.1800e-04 - val_accuracy: 0.7740\n",
      "Epoch 50/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.1621e-04 - accuracy: 0.7755 - val_loss: 1.1445e-04 - val_accuracy: 0.7780\n",
      "Epoch 51/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 1.1265e-04 - accuracy: 0.7815 - val_loss: 1.1085e-04 - val_accuracy: 0.7837\n",
      "Epoch 52/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 1.0906e-04 - accuracy: 0.7871 - val_loss: 1.0724e-04 - val_accuracy: 0.7903\n",
      "Epoch 53/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 1.0547e-04 - accuracy: 0.7922 - val_loss: 1.0362e-04 - val_accuracy: 0.7973\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 11us/step - loss: 1.0189e-04 - accuracy: 0.7994 - val_loss: 1.0003e-04 - val_accuracy: 0.8040\n",
      "Epoch 55/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 9.8313e-05 - accuracy: 0.8060 - val_loss: 9.6512e-05 - val_accuracy: 0.8107\n",
      "Epoch 56/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 9.4850e-05 - accuracy: 0.8134 - val_loss: 9.3086e-05 - val_accuracy: 0.8137\n",
      "Epoch 57/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 9.1466e-05 - accuracy: 0.8186 - val_loss: 8.9789e-05 - val_accuracy: 0.8190\n",
      "Epoch 58/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 8.8246e-05 - accuracy: 0.8245 - val_loss: 8.6631e-05 - val_accuracy: 0.8240\n",
      "Epoch 59/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 8.5180e-05 - accuracy: 0.8305 - val_loss: 8.3643e-05 - val_accuracy: 0.8313\n",
      "Epoch 60/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 8.2250e-05 - accuracy: 0.8384 - val_loss: 8.0843e-05 - val_accuracy: 0.8357\n",
      "Epoch 61/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 7.9535e-05 - accuracy: 0.8420 - val_loss: 7.8227e-05 - val_accuracy: 0.8410\n",
      "Epoch 62/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 7.6988e-05 - accuracy: 0.8462 - val_loss: 7.5817e-05 - val_accuracy: 0.8450\n",
      "Epoch 63/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 7.4650e-05 - accuracy: 0.8505 - val_loss: 7.3603e-05 - val_accuracy: 0.8497\n",
      "Epoch 64/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 7.2524e-05 - accuracy: 0.8550 - val_loss: 7.1578e-05 - val_accuracy: 0.8573\n",
      "Epoch 65/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 7.0545e-05 - accuracy: 0.8597 - val_loss: 6.9745e-05 - val_accuracy: 0.8633\n",
      "Epoch 66/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 6.8779e-05 - accuracy: 0.8649 - val_loss: 6.8079e-05 - val_accuracy: 0.8697\n",
      "Epoch 67/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 6.7186e-05 - accuracy: 0.8681 - val_loss: 6.6579e-05 - val_accuracy: 0.8717\n",
      "Epoch 68/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 6.5740e-05 - accuracy: 0.8720 - val_loss: 6.5237e-05 - val_accuracy: 0.8747\n",
      "Epoch 69/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 6.4460e-05 - accuracy: 0.8739 - val_loss: 6.4034e-05 - val_accuracy: 0.8787\n",
      "Epoch 70/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 6.3299e-05 - accuracy: 0.8767 - val_loss: 6.2962e-05 - val_accuracy: 0.8810\n",
      "Epoch 71/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 6.2271e-05 - accuracy: 0.8806 - val_loss: 6.2009e-05 - val_accuracy: 0.8847\n",
      "Epoch 72/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 6.1356e-05 - accuracy: 0.8836 - val_loss: 6.1168e-05 - val_accuracy: 0.8890\n",
      "Epoch 73/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 6.0551e-05 - accuracy: 0.8864 - val_loss: 6.0420e-05 - val_accuracy: 0.8917\n",
      "Epoch 74/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.9842e-05 - accuracy: 0.8903 - val_loss: 5.9758e-05 - val_accuracy: 0.8947\n",
      "Epoch 75/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.9206e-05 - accuracy: 0.8938 - val_loss: 5.9173e-05 - val_accuracy: 0.8963\n",
      "Epoch 76/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.8647e-05 - accuracy: 0.8953 - val_loss: 5.8658e-05 - val_accuracy: 0.8963\n",
      "Epoch 77/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.8151e-05 - accuracy: 0.8967 - val_loss: 5.8199e-05 - val_accuracy: 0.8983\n",
      "Epoch 78/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.7715e-05 - accuracy: 0.8985 - val_loss: 5.7796e-05 - val_accuracy: 0.9000\n",
      "Epoch 79/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.7333e-05 - accuracy: 0.9014 - val_loss: 5.7440e-05 - val_accuracy: 0.9037\n",
      "Epoch 80/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.6994e-05 - accuracy: 0.9015 - val_loss: 5.7125e-05 - val_accuracy: 0.9070\n",
      "Epoch 81/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.6690e-05 - accuracy: 0.9034 - val_loss: 5.6846e-05 - val_accuracy: 0.9087\n",
      "Epoch 82/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.6425e-05 - accuracy: 0.9053 - val_loss: 5.6597e-05 - val_accuracy: 0.9103\n",
      "Epoch 83/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.6186e-05 - accuracy: 0.9064 - val_loss: 5.6372e-05 - val_accuracy: 0.9117\n",
      "Epoch 84/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.5975e-05 - accuracy: 0.9078 - val_loss: 5.6179e-05 - val_accuracy: 0.9130\n",
      "Epoch 85/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.5788e-05 - accuracy: 0.9090 - val_loss: 5.6003e-05 - val_accuracy: 0.9140\n",
      "Epoch 86/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.5619e-05 - accuracy: 0.9097 - val_loss: 5.5845e-05 - val_accuracy: 0.9140\n",
      "Epoch 87/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.5469e-05 - accuracy: 0.9109 - val_loss: 5.5704e-05 - val_accuracy: 0.9163\n",
      "Epoch 88/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.5334e-05 - accuracy: 0.9120 - val_loss: 5.5575e-05 - val_accuracy: 0.9170\n",
      "Epoch 89/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.5213e-05 - accuracy: 0.9122 - val_loss: 5.5463e-05 - val_accuracy: 0.9173\n",
      "Epoch 90/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.5102e-05 - accuracy: 0.9131 - val_loss: 5.5361e-05 - val_accuracy: 0.9177\n",
      "Epoch 91/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.5003e-05 - accuracy: 0.9134 - val_loss: 5.5267e-05 - val_accuracy: 0.9177\n",
      "Epoch 92/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.4911e-05 - accuracy: 0.9145 - val_loss: 5.5180e-05 - val_accuracy: 0.9190\n",
      "Epoch 93/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4828e-05 - accuracy: 0.9154 - val_loss: 5.5099e-05 - val_accuracy: 0.9197\n",
      "Epoch 94/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4753e-05 - accuracy: 0.9150 - val_loss: 5.5026e-05 - val_accuracy: 0.9203\n",
      "Epoch 95/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4683e-05 - accuracy: 0.9151 - val_loss: 5.4959e-05 - val_accuracy: 0.9213\n",
      "Epoch 96/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4618e-05 - accuracy: 0.9160 - val_loss: 5.4896e-05 - val_accuracy: 0.9220\n",
      "Epoch 97/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4557e-05 - accuracy: 0.9168 - val_loss: 5.4840e-05 - val_accuracy: 0.9210\n",
      "Epoch 98/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.4502e-05 - accuracy: 0.9172 - val_loss: 5.4786e-05 - val_accuracy: 0.9220\n",
      "Epoch 99/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.4451e-05 - accuracy: 0.9164 - val_loss: 5.4735e-05 - val_accuracy: 0.9223\n",
      "Epoch 100/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4401e-05 - accuracy: 0.9166 - val_loss: 5.4686e-05 - val_accuracy: 0.9237\n",
      "Epoch 101/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.4354e-05 - accuracy: 0.9169 - val_loss: 5.4643e-05 - val_accuracy: 0.9237\n",
      "Epoch 102/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4309e-05 - accuracy: 0.9170 - val_loss: 5.4598e-05 - val_accuracy: 0.9230\n",
      "Epoch 103/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4268e-05 - accuracy: 0.9184 - val_loss: 5.4557e-05 - val_accuracy: 0.9230\n",
      "Epoch 104/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.4229e-05 - accuracy: 0.9187 - val_loss: 5.4518e-05 - val_accuracy: 0.9240\n",
      "Epoch 105/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4191e-05 - accuracy: 0.9189 - val_loss: 5.4480e-05 - val_accuracy: 0.9253\n",
      "Epoch 106/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.4155e-05 - accuracy: 0.9196 - val_loss: 5.4445e-05 - val_accuracy: 0.9253\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.4121e-05 - accuracy: 0.9194 - val_loss: 5.4408e-05 - val_accuracy: 0.9253\n",
      "Epoch 108/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.4087e-05 - accuracy: 0.9196 - val_loss: 5.4374e-05 - val_accuracy: 0.9253\n",
      "Epoch 109/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.4055e-05 - accuracy: 0.9197 - val_loss: 5.4344e-05 - val_accuracy: 0.9250\n",
      "Epoch 110/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.4022e-05 - accuracy: 0.9201 - val_loss: 5.4311e-05 - val_accuracy: 0.9253\n",
      "Epoch 111/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.3992e-05 - accuracy: 0.9201 - val_loss: 5.4281e-05 - val_accuracy: 0.9257\n",
      "Epoch 112/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3963e-05 - accuracy: 0.9208 - val_loss: 5.4250e-05 - val_accuracy: 0.9270\n",
      "Epoch 113/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.3934e-05 - accuracy: 0.9212 - val_loss: 5.4222e-05 - val_accuracy: 0.9270\n",
      "Epoch 114/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.3903e-05 - accuracy: 0.9215 - val_loss: 5.4195e-05 - val_accuracy: 0.9260\n",
      "Epoch 115/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.3877e-05 - accuracy: 0.9216 - val_loss: 5.4166e-05 - val_accuracy: 0.9270\n",
      "Epoch 116/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3850e-05 - accuracy: 0.9218 - val_loss: 5.4138e-05 - val_accuracy: 0.9260\n",
      "Epoch 117/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3823e-05 - accuracy: 0.9212 - val_loss: 5.4109e-05 - val_accuracy: 0.9260\n",
      "Epoch 118/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3798e-05 - accuracy: 0.9221 - val_loss: 5.4086e-05 - val_accuracy: 0.9263\n",
      "Epoch 119/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.3771e-05 - accuracy: 0.9226 - val_loss: 5.4061e-05 - val_accuracy: 0.9267\n",
      "Epoch 120/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3744e-05 - accuracy: 0.9227 - val_loss: 5.4035e-05 - val_accuracy: 0.9267\n",
      "Epoch 121/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3720e-05 - accuracy: 0.9222 - val_loss: 5.4007e-05 - val_accuracy: 0.9263\n",
      "Epoch 122/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3696e-05 - accuracy: 0.9229 - val_loss: 5.3981e-05 - val_accuracy: 0.9263\n",
      "Epoch 123/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3671e-05 - accuracy: 0.9229 - val_loss: 5.3955e-05 - val_accuracy: 0.9270\n",
      "Epoch 124/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.3646e-05 - accuracy: 0.9233 - val_loss: 5.3931e-05 - val_accuracy: 0.9267\n",
      "Epoch 125/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.3624e-05 - accuracy: 0.9229 - val_loss: 5.3907e-05 - val_accuracy: 0.9253\n",
      "Epoch 126/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3600e-05 - accuracy: 0.9237 - val_loss: 5.3889e-05 - val_accuracy: 0.9253\n",
      "Epoch 127/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.3577e-05 - accuracy: 0.9237 - val_loss: 5.3863e-05 - val_accuracy: 0.9257\n",
      "Epoch 128/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3554e-05 - accuracy: 0.9240 - val_loss: 5.3839e-05 - val_accuracy: 0.9273\n",
      "Epoch 129/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3531e-05 - accuracy: 0.9237 - val_loss: 5.3813e-05 - val_accuracy: 0.9260\n",
      "Epoch 130/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3509e-05 - accuracy: 0.9241 - val_loss: 5.3792e-05 - val_accuracy: 0.9260\n",
      "Epoch 131/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3486e-05 - accuracy: 0.9241 - val_loss: 5.3771e-05 - val_accuracy: 0.9253\n",
      "Epoch 132/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3464e-05 - accuracy: 0.9244 - val_loss: 5.3747e-05 - val_accuracy: 0.9260\n",
      "Epoch 133/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3442e-05 - accuracy: 0.9241 - val_loss: 5.3725e-05 - val_accuracy: 0.9267\n",
      "Epoch 134/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3421e-05 - accuracy: 0.9240 - val_loss: 5.3704e-05 - val_accuracy: 0.9270\n",
      "Epoch 135/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3400e-05 - accuracy: 0.9243 - val_loss: 5.3683e-05 - val_accuracy: 0.9267\n",
      "Epoch 136/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.3379e-05 - accuracy: 0.9246 - val_loss: 5.3658e-05 - val_accuracy: 0.9253\n",
      "Epoch 137/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.3356e-05 - accuracy: 0.9251 - val_loss: 5.3637e-05 - val_accuracy: 0.9267\n",
      "Epoch 138/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3338e-05 - accuracy: 0.9249 - val_loss: 5.3616e-05 - val_accuracy: 0.9260\n",
      "Epoch 139/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.3316e-05 - accuracy: 0.9252 - val_loss: 5.3597e-05 - val_accuracy: 0.9260\n",
      "Epoch 140/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3296e-05 - accuracy: 0.9249 - val_loss: 5.3575e-05 - val_accuracy: 0.9270\n",
      "Epoch 141/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.3275e-05 - accuracy: 0.9254 - val_loss: 5.3555e-05 - val_accuracy: 0.9263\n",
      "Epoch 142/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3256e-05 - accuracy: 0.9258 - val_loss: 5.3536e-05 - val_accuracy: 0.9270\n",
      "Epoch 143/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3234e-05 - accuracy: 0.9256 - val_loss: 5.3514e-05 - val_accuracy: 0.9270\n",
      "Epoch 144/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3216e-05 - accuracy: 0.9259 - val_loss: 5.3496e-05 - val_accuracy: 0.9267\n",
      "Epoch 145/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3195e-05 - accuracy: 0.9261 - val_loss: 5.3476e-05 - val_accuracy: 0.9270\n",
      "Epoch 146/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.3176e-05 - accuracy: 0.9261 - val_loss: 5.3452e-05 - val_accuracy: 0.9270\n",
      "Epoch 147/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3156e-05 - accuracy: 0.9262 - val_loss: 5.3430e-05 - val_accuracy: 0.9280\n",
      "Epoch 148/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3137e-05 - accuracy: 0.9262 - val_loss: 5.3413e-05 - val_accuracy: 0.9287\n",
      "Epoch 149/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.3117e-05 - accuracy: 0.9269 - val_loss: 5.3395e-05 - val_accuracy: 0.9287\n",
      "Epoch 150/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3099e-05 - accuracy: 0.9265 - val_loss: 5.3375e-05 - val_accuracy: 0.9280\n",
      "Epoch 151/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3079e-05 - accuracy: 0.9262 - val_loss: 5.3357e-05 - val_accuracy: 0.9287\n",
      "Epoch 152/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.3060e-05 - accuracy: 0.9271 - val_loss: 5.3335e-05 - val_accuracy: 0.9287\n",
      "Epoch 153/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.3042e-05 - accuracy: 0.9269 - val_loss: 5.3316e-05 - val_accuracy: 0.9273\n",
      "Epoch 154/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.3023e-05 - accuracy: 0.9274 - val_loss: 5.3298e-05 - val_accuracy: 0.9280\n",
      "Epoch 155/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.3005e-05 - accuracy: 0.9273 - val_loss: 5.3279e-05 - val_accuracy: 0.9280\n",
      "Epoch 156/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.2986e-05 - accuracy: 0.9277 - val_loss: 5.3261e-05 - val_accuracy: 0.9283\n",
      "Epoch 157/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.2968e-05 - accuracy: 0.9271 - val_loss: 5.3242e-05 - val_accuracy: 0.9287\n",
      "Epoch 158/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2951e-05 - accuracy: 0.9275 - val_loss: 5.3221e-05 - val_accuracy: 0.9297\n",
      "Epoch 159/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.2932e-05 - accuracy: 0.9268 - val_loss: 5.3205e-05 - val_accuracy: 0.9287\n",
      "Epoch 160/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2915e-05 - accuracy: 0.9276 - val_loss: 5.3189e-05 - val_accuracy: 0.9293\n",
      "Epoch 161/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.2898e-05 - accuracy: 0.9276 - val_loss: 5.3172e-05 - val_accuracy: 0.9283\n",
      "Epoch 162/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2880e-05 - accuracy: 0.9274 - val_loss: 5.3154e-05 - val_accuracy: 0.9290\n",
      "Epoch 163/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2862e-05 - accuracy: 0.9277 - val_loss: 5.3135e-05 - val_accuracy: 0.9290\n",
      "Epoch 164/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2845e-05 - accuracy: 0.9274 - val_loss: 5.3116e-05 - val_accuracy: 0.9283\n",
      "Epoch 165/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.2827e-05 - accuracy: 0.9275 - val_loss: 5.3099e-05 - val_accuracy: 0.9297\n",
      "Epoch 166/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2811e-05 - accuracy: 0.9280 - val_loss: 5.3081e-05 - val_accuracy: 0.9293\n",
      "Epoch 167/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2793e-05 - accuracy: 0.9277 - val_loss: 5.3062e-05 - val_accuracy: 0.9287\n",
      "Epoch 168/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2776e-05 - accuracy: 0.9277 - val_loss: 5.3048e-05 - val_accuracy: 0.9297\n",
      "Epoch 169/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.2761e-05 - accuracy: 0.9281 - val_loss: 5.3033e-05 - val_accuracy: 0.9303\n",
      "Epoch 170/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.2743e-05 - accuracy: 0.9285 - val_loss: 5.3013e-05 - val_accuracy: 0.9297\n",
      "Epoch 171/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.2727e-05 - accuracy: 0.9290 - val_loss: 5.2994e-05 - val_accuracy: 0.9293\n",
      "Epoch 172/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.2710e-05 - accuracy: 0.9286 - val_loss: 5.2981e-05 - val_accuracy: 0.9307\n",
      "Epoch 173/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.2694e-05 - accuracy: 0.9287 - val_loss: 5.2961e-05 - val_accuracy: 0.9297\n",
      "Epoch 174/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2677e-05 - accuracy: 0.9280 - val_loss: 5.2946e-05 - val_accuracy: 0.9300\n",
      "Epoch 175/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.2662e-05 - accuracy: 0.9279 - val_loss: 5.2934e-05 - val_accuracy: 0.9293\n",
      "Epoch 176/500\n",
      "8000/8000 [==============================] - 0s 28us/step - loss: 5.2646e-05 - accuracy: 0.9286 - val_loss: 5.2911e-05 - val_accuracy: 0.9287\n",
      "Epoch 177/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2629e-05 - accuracy: 0.9287 - val_loss: 5.2894e-05 - val_accuracy: 0.9290\n",
      "Epoch 178/500\n",
      "8000/8000 [==============================] - 0s 20us/step - loss: 5.2613e-05 - accuracy: 0.9287 - val_loss: 5.2882e-05 - val_accuracy: 0.9297\n",
      "Epoch 179/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.2597e-05 - accuracy: 0.9290 - val_loss: 5.2866e-05 - val_accuracy: 0.9290\n",
      "Epoch 180/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2582e-05 - accuracy: 0.9286 - val_loss: 5.2849e-05 - val_accuracy: 0.9303\n",
      "Epoch 181/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2569e-05 - accuracy: 0.9281 - val_loss: 5.2833e-05 - val_accuracy: 0.9307\n",
      "Epoch 182/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2551e-05 - accuracy: 0.9284 - val_loss: 5.2819e-05 - val_accuracy: 0.9303\n",
      "Epoch 183/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.2536e-05 - accuracy: 0.9286 - val_loss: 5.2801e-05 - val_accuracy: 0.9297\n",
      "Epoch 184/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2520e-05 - accuracy: 0.9286 - val_loss: 5.2784e-05 - val_accuracy: 0.9303\n",
      "Epoch 185/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2505e-05 - accuracy: 0.9289 - val_loss: 5.2772e-05 - val_accuracy: 0.9303\n",
      "Epoch 186/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2489e-05 - accuracy: 0.9287 - val_loss: 5.2755e-05 - val_accuracy: 0.9307\n",
      "Epoch 187/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2476e-05 - accuracy: 0.9286 - val_loss: 5.2736e-05 - val_accuracy: 0.9297\n",
      "Epoch 188/500\n",
      "8000/8000 [==============================] - 0s 21us/step - loss: 5.2460e-05 - accuracy: 0.9299 - val_loss: 5.2728e-05 - val_accuracy: 0.9290\n",
      "Epoch 189/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.2446e-05 - accuracy: 0.9296 - val_loss: 5.2709e-05 - val_accuracy: 0.9297\n",
      "Epoch 190/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2431e-05 - accuracy: 0.9289 - val_loss: 5.2696e-05 - val_accuracy: 0.9307\n",
      "Epoch 191/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2416e-05 - accuracy: 0.9289 - val_loss: 5.2681e-05 - val_accuracy: 0.9303\n",
      "Epoch 192/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.2401e-05 - accuracy: 0.9300 - val_loss: 5.2663e-05 - val_accuracy: 0.9307\n",
      "Epoch 193/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2386e-05 - accuracy: 0.9290 - val_loss: 5.2650e-05 - val_accuracy: 0.9303\n",
      "Epoch 194/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2372e-05 - accuracy: 0.9300 - val_loss: 5.2634e-05 - val_accuracy: 0.9320\n",
      "Epoch 195/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2357e-05 - accuracy: 0.9296 - val_loss: 5.2620e-05 - val_accuracy: 0.9310\n",
      "Epoch 196/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.2344e-05 - accuracy: 0.9291 - val_loss: 5.2607e-05 - val_accuracy: 0.9300\n",
      "Epoch 197/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2329e-05 - accuracy: 0.9299 - val_loss: 5.2590e-05 - val_accuracy: 0.9303\n",
      "Epoch 198/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.2315e-05 - accuracy: 0.9300 - val_loss: 5.2578e-05 - val_accuracy: 0.9307\n",
      "Epoch 199/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2302e-05 - accuracy: 0.9305 - val_loss: 5.2564e-05 - val_accuracy: 0.9313\n",
      "Epoch 200/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2288e-05 - accuracy: 0.9296 - val_loss: 5.2547e-05 - val_accuracy: 0.9310\n",
      "Epoch 201/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2274e-05 - accuracy: 0.9304 - val_loss: 5.2535e-05 - val_accuracy: 0.9310\n",
      "Epoch 202/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2260e-05 - accuracy: 0.9301 - val_loss: 5.2520e-05 - val_accuracy: 0.9313\n",
      "Epoch 203/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2246e-05 - accuracy: 0.9304 - val_loss: 5.2503e-05 - val_accuracy: 0.9313\n",
      "Epoch 204/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.2232e-05 - accuracy: 0.9298 - val_loss: 5.2494e-05 - val_accuracy: 0.9313\n",
      "Epoch 205/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2218e-05 - accuracy: 0.9300 - val_loss: 5.2480e-05 - val_accuracy: 0.9310\n",
      "Epoch 206/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2206e-05 - accuracy: 0.9306 - val_loss: 5.2468e-05 - val_accuracy: 0.9317\n",
      "Epoch 207/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.2193e-05 - accuracy: 0.9295 - val_loss: 5.2453e-05 - val_accuracy: 0.9317\n",
      "Epoch 208/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.2179e-05 - accuracy: 0.9306 - val_loss: 5.2438e-05 - val_accuracy: 0.9317\n",
      "Epoch 209/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.2166e-05 - accuracy: 0.9302 - val_loss: 5.2424e-05 - val_accuracy: 0.9320\n",
      "Epoch 210/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.2155e-05 - accuracy: 0.9294 - val_loss: 5.2411e-05 - val_accuracy: 0.9307\n",
      "Epoch 211/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2141e-05 - accuracy: 0.9304 - val_loss: 5.2396e-05 - val_accuracy: 0.9320\n",
      "Epoch 212/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.2129e-05 - accuracy: 0.9306 - val_loss: 5.2384e-05 - val_accuracy: 0.9320\n",
      "Epoch 213/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2113e-05 - accuracy: 0.9306 - val_loss: 5.2376e-05 - val_accuracy: 0.9313\n",
      "Epoch 214/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2102e-05 - accuracy: 0.9304 - val_loss: 5.2357e-05 - val_accuracy: 0.9307\n",
      "Epoch 215/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.2090e-05 - accuracy: 0.9308 - val_loss: 5.2348e-05 - val_accuracy: 0.9310\n",
      "Epoch 216/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.2076e-05 - accuracy: 0.9309 - val_loss: 5.2331e-05 - val_accuracy: 0.9320\n",
      "Epoch 217/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2064e-05 - accuracy: 0.9309 - val_loss: 5.2317e-05 - val_accuracy: 0.9310\n",
      "Epoch 218/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.2051e-05 - accuracy: 0.9306 - val_loss: 5.2306e-05 - val_accuracy: 0.9317\n",
      "Epoch 219/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2040e-05 - accuracy: 0.9306 - val_loss: 5.2296e-05 - val_accuracy: 0.9333\n",
      "Epoch 220/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.2027e-05 - accuracy: 0.9306 - val_loss: 5.2284e-05 - val_accuracy: 0.9330\n",
      "Epoch 221/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.2014e-05 - accuracy: 0.9304 - val_loss: 5.2268e-05 - val_accuracy: 0.9320\n",
      "Epoch 222/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.2001e-05 - accuracy: 0.9305 - val_loss: 5.2257e-05 - val_accuracy: 0.9333\n",
      "Epoch 223/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.1990e-05 - accuracy: 0.9312 - val_loss: 5.2242e-05 - val_accuracy: 0.9330\n",
      "Epoch 224/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.1978e-05 - accuracy: 0.9314 - val_loss: 5.2229e-05 - val_accuracy: 0.9333\n",
      "Epoch 225/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1967e-05 - accuracy: 0.9315 - val_loss: 5.2222e-05 - val_accuracy: 0.9340\n",
      "Epoch 226/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.1953e-05 - accuracy: 0.9312 - val_loss: 5.2208e-05 - val_accuracy: 0.9330\n",
      "Epoch 227/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1941e-05 - accuracy: 0.9306 - val_loss: 5.2193e-05 - val_accuracy: 0.9320\n",
      "Epoch 228/500\n",
      "8000/8000 [==============================] - 0s 19us/step - loss: 5.1929e-05 - accuracy: 0.9314 - val_loss: 5.2182e-05 - val_accuracy: 0.9323\n",
      "Epoch 229/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.1916e-05 - accuracy: 0.9315 - val_loss: 5.2169e-05 - val_accuracy: 0.9333\n",
      "Epoch 230/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.1907e-05 - accuracy: 0.9311 - val_loss: 5.2161e-05 - val_accuracy: 0.9333\n",
      "Epoch 231/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.1894e-05 - accuracy: 0.9319 - val_loss: 5.2146e-05 - val_accuracy: 0.9327\n",
      "Epoch 232/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1881e-05 - accuracy: 0.9310 - val_loss: 5.2133e-05 - val_accuracy: 0.9333\n",
      "Epoch 233/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1870e-05 - accuracy: 0.9316 - val_loss: 5.2122e-05 - val_accuracy: 0.9323\n",
      "Epoch 234/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1858e-05 - accuracy: 0.9324 - val_loss: 5.2109e-05 - val_accuracy: 0.9340\n",
      "Epoch 235/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1848e-05 - accuracy: 0.9312 - val_loss: 5.2099e-05 - val_accuracy: 0.9327\n",
      "Epoch 236/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1835e-05 - accuracy: 0.9314 - val_loss: 5.2091e-05 - val_accuracy: 0.9333\n",
      "Epoch 237/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1825e-05 - accuracy: 0.9320 - val_loss: 5.2075e-05 - val_accuracy: 0.9327\n",
      "Epoch 238/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1812e-05 - accuracy: 0.9316 - val_loss: 5.2063e-05 - val_accuracy: 0.9330\n",
      "Epoch 239/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1801e-05 - accuracy: 0.9315 - val_loss: 5.2052e-05 - val_accuracy: 0.9350\n",
      "Epoch 240/500\n",
      "8000/8000 [==============================] - 0s 21us/step - loss: 5.1790e-05 - accuracy: 0.9324 - val_loss: 5.2042e-05 - val_accuracy: 0.9343\n",
      "Epoch 241/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1779e-05 - accuracy: 0.9331 - val_loss: 5.2030e-05 - val_accuracy: 0.9343\n",
      "Epoch 242/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.1766e-05 - accuracy: 0.9329 - val_loss: 5.2016e-05 - val_accuracy: 0.9327\n",
      "Epoch 243/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1758e-05 - accuracy: 0.9331 - val_loss: 5.2007e-05 - val_accuracy: 0.9333\n",
      "Epoch 244/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1745e-05 - accuracy: 0.9324 - val_loss: 5.1996e-05 - val_accuracy: 0.9333\n",
      "Epoch 245/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.1735e-05 - accuracy: 0.9314 - val_loss: 5.1984e-05 - val_accuracy: 0.9337\n",
      "Epoch 246/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.1724e-05 - accuracy: 0.9315 - val_loss: 5.1974e-05 - val_accuracy: 0.9337\n",
      "Epoch 247/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1714e-05 - accuracy: 0.9319 - val_loss: 5.1964e-05 - val_accuracy: 0.9340\n",
      "Epoch 248/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1703e-05 - accuracy: 0.9320 - val_loss: 5.1950e-05 - val_accuracy: 0.9350\n",
      "Epoch 249/500\n",
      "8000/8000 [==============================] - 0s 19us/step - loss: 5.1695e-05 - accuracy: 0.9325 - val_loss: 5.1942e-05 - val_accuracy: 0.9347\n",
      "Epoch 250/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.1683e-05 - accuracy: 0.9335 - val_loss: 5.1931e-05 - val_accuracy: 0.9327\n",
      "Epoch 251/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.1672e-05 - accuracy: 0.9327 - val_loss: 5.1918e-05 - val_accuracy: 0.9340\n",
      "Epoch 252/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1661e-05 - accuracy: 0.9324 - val_loss: 5.1908e-05 - val_accuracy: 0.9337\n",
      "Epoch 253/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.1651e-05 - accuracy: 0.9333 - val_loss: 5.1898e-05 - val_accuracy: 0.9337\n",
      "Epoch 254/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.1641e-05 - accuracy: 0.9326 - val_loss: 5.1885e-05 - val_accuracy: 0.9337\n",
      "Epoch 255/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1630e-05 - accuracy: 0.9330 - val_loss: 5.1876e-05 - val_accuracy: 0.9340\n",
      "Epoch 256/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.1619e-05 - accuracy: 0.9331 - val_loss: 5.1868e-05 - val_accuracy: 0.9347\n",
      "Epoch 257/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.1610e-05 - accuracy: 0.9334 - val_loss: 5.1856e-05 - val_accuracy: 0.9333\n",
      "Epoch 258/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.1599e-05 - accuracy: 0.9325 - val_loss: 5.1847e-05 - val_accuracy: 0.9340\n",
      "Epoch 259/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1590e-05 - accuracy: 0.9336 - val_loss: 5.1833e-05 - val_accuracy: 0.9347\n",
      "Epoch 260/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1580e-05 - accuracy: 0.9345 - val_loss: 5.1824e-05 - val_accuracy: 0.9347\n",
      "Epoch 261/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1569e-05 - accuracy: 0.9336 - val_loss: 5.1818e-05 - val_accuracy: 0.9340\n",
      "Epoch 262/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1559e-05 - accuracy: 0.9334 - val_loss: 5.1802e-05 - val_accuracy: 0.9343\n",
      "Epoch 263/500\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 5.1451e-05 - accuracy: 0.93 - 0s 22us/step - loss: 5.1549e-05 - accuracy: 0.9334 - val_loss: 5.1798e-05 - val_accuracy: 0.9353\n",
      "Epoch 264/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1539e-05 - accuracy: 0.9335 - val_loss: 5.1782e-05 - val_accuracy: 0.9337\n",
      "Epoch 265/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1530e-05 - accuracy: 0.9346 - val_loss: 5.1773e-05 - val_accuracy: 0.9333\n",
      "Epoch 266/500\n",
      "8000/8000 [==============================] - 0s 20us/step - loss: 5.1519e-05 - accuracy: 0.9327 - val_loss: 5.1764e-05 - val_accuracy: 0.9347\n",
      "Epoch 267/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1510e-05 - accuracy: 0.9335 - val_loss: 5.1753e-05 - val_accuracy: 0.9347\n",
      "Epoch 268/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1500e-05 - accuracy: 0.9341 - val_loss: 5.1743e-05 - val_accuracy: 0.9347\n",
      "Epoch 269/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1490e-05 - accuracy: 0.9336 - val_loss: 5.1735e-05 - val_accuracy: 0.9343\n",
      "Epoch 270/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1480e-05 - accuracy: 0.9336 - val_loss: 5.1724e-05 - val_accuracy: 0.9353\n",
      "Epoch 271/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1469e-05 - accuracy: 0.9336 - val_loss: 5.1711e-05 - val_accuracy: 0.9350\n",
      "Epoch 272/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1461e-05 - accuracy: 0.9345 - val_loss: 5.1704e-05 - val_accuracy: 0.9333\n",
      "Epoch 273/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1451e-05 - accuracy: 0.9339 - val_loss: 5.1696e-05 - val_accuracy: 0.9340\n",
      "Epoch 274/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1443e-05 - accuracy: 0.9342 - val_loss: 5.1682e-05 - val_accuracy: 0.9353\n",
      "Epoch 275/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1433e-05 - accuracy: 0.9339 - val_loss: 5.1679e-05 - val_accuracy: 0.9353\n",
      "Epoch 276/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1425e-05 - accuracy: 0.9346 - val_loss: 5.1662e-05 - val_accuracy: 0.9333\n",
      "Epoch 277/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1414e-05 - accuracy: 0.9340 - val_loss: 5.1656e-05 - val_accuracy: 0.9357\n",
      "Epoch 278/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.1406e-05 - accuracy: 0.9344 - val_loss: 5.1649e-05 - val_accuracy: 0.9347\n",
      "Epoch 279/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1395e-05 - accuracy: 0.9358 - val_loss: 5.1636e-05 - val_accuracy: 0.9347\n",
      "Epoch 280/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1387e-05 - accuracy: 0.9340 - val_loss: 5.1623e-05 - val_accuracy: 0.9350\n",
      "Epoch 281/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1376e-05 - accuracy: 0.9337 - val_loss: 5.1618e-05 - val_accuracy: 0.9337\n",
      "Epoch 282/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1368e-05 - accuracy: 0.9355 - val_loss: 5.1608e-05 - val_accuracy: 0.9343\n",
      "Epoch 283/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1359e-05 - accuracy: 0.9341 - val_loss: 5.1599e-05 - val_accuracy: 0.9350\n",
      "Epoch 284/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1349e-05 - accuracy: 0.9346 - val_loss: 5.1593e-05 - val_accuracy: 0.9357\n",
      "Epoch 285/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1342e-05 - accuracy: 0.9339 - val_loss: 5.1577e-05 - val_accuracy: 0.9350\n",
      "Epoch 286/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.1332e-05 - accuracy: 0.9344 - val_loss: 5.1572e-05 - val_accuracy: 0.9353\n",
      "Epoch 287/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.1324e-05 - accuracy: 0.9349 - val_loss: 5.1565e-05 - val_accuracy: 0.9340\n",
      "Epoch 288/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.1314e-05 - accuracy: 0.9345 - val_loss: 5.1553e-05 - val_accuracy: 0.9343\n",
      "Epoch 289/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.1304e-05 - accuracy: 0.9346 - val_loss: 5.1544e-05 - val_accuracy: 0.9343\n",
      "Epoch 290/500\n",
      "8000/8000 [==============================] - 0s 19us/step - loss: 5.1298e-05 - accuracy: 0.9356 - val_loss: 5.1537e-05 - val_accuracy: 0.9340\n",
      "Epoch 291/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.1288e-05 - accuracy: 0.9350 - val_loss: 5.1526e-05 - val_accuracy: 0.9343\n",
      "Epoch 292/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1277e-05 - accuracy: 0.9351 - val_loss: 5.1521e-05 - val_accuracy: 0.9340\n",
      "Epoch 293/500\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 5.0860e-05 - accuracy: 0.92 - 0s 12us/step - loss: 5.1272e-05 - accuracy: 0.9361 - val_loss: 5.1506e-05 - val_accuracy: 0.9337\n",
      "Epoch 294/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.1261e-05 - accuracy: 0.9354 - val_loss: 5.1496e-05 - val_accuracy: 0.9347\n",
      "Epoch 295/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.1251e-05 - accuracy: 0.9352 - val_loss: 5.1494e-05 - val_accuracy: 0.9360\n",
      "Epoch 296/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.1245e-05 - accuracy: 0.9358 - val_loss: 5.1480e-05 - val_accuracy: 0.9347\n",
      "Epoch 297/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1237e-05 - accuracy: 0.9344 - val_loss: 5.1469e-05 - val_accuracy: 0.9347\n",
      "Epoch 298/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.1230e-05 - accuracy: 0.9365 - val_loss: 5.1466e-05 - val_accuracy: 0.9343\n",
      "Epoch 299/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.1221e-05 - accuracy: 0.9370 - val_loss: 5.1455e-05 - val_accuracy: 0.9343\n",
      "Epoch 300/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1212e-05 - accuracy: 0.9350 - val_loss: 5.1452e-05 - val_accuracy: 0.9347\n",
      "Epoch 301/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1202e-05 - accuracy: 0.9352 - val_loss: 5.1439e-05 - val_accuracy: 0.9353\n",
      "Epoch 302/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1192e-05 - accuracy: 0.9356 - val_loss: 5.1432e-05 - val_accuracy: 0.9357\n",
      "Epoch 303/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1184e-05 - accuracy: 0.9351 - val_loss: 5.1421e-05 - val_accuracy: 0.9347\n",
      "Epoch 304/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1177e-05 - accuracy: 0.9364 - val_loss: 5.1414e-05 - val_accuracy: 0.9337\n",
      "Epoch 305/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1168e-05 - accuracy: 0.9367 - val_loss: 5.1405e-05 - val_accuracy: 0.9353\n",
      "Epoch 306/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.1163e-05 - accuracy: 0.9361 - val_loss: 5.1395e-05 - val_accuracy: 0.9343\n",
      "Epoch 307/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1153e-05 - accuracy: 0.9351 - val_loss: 5.1388e-05 - val_accuracy: 0.9350\n",
      "Epoch 308/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.1148e-05 - accuracy: 0.9358 - val_loss: 5.1380e-05 - val_accuracy: 0.9350\n",
      "Epoch 309/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.1137e-05 - accuracy: 0.9358 - val_loss: 5.1374e-05 - val_accuracy: 0.9343\n",
      "Epoch 310/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1130e-05 - accuracy: 0.9350 - val_loss: 5.1364e-05 - val_accuracy: 0.9350\n",
      "Epoch 311/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1122e-05 - accuracy: 0.9361 - val_loss: 5.1354e-05 - val_accuracy: 0.9353\n",
      "Epoch 312/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.1113e-05 - accuracy: 0.9359 - val_loss: 5.1347e-05 - val_accuracy: 0.9360\n",
      "Epoch 313/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1106e-05 - accuracy: 0.9355 - val_loss: 5.1335e-05 - val_accuracy: 0.9357\n",
      "Epoch 314/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1098e-05 - accuracy: 0.9360 - val_loss: 5.1330e-05 - val_accuracy: 0.9343\n",
      "Epoch 315/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1088e-05 - accuracy: 0.9366 - val_loss: 5.1318e-05 - val_accuracy: 0.9347\n",
      "Epoch 316/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1081e-05 - accuracy: 0.9356 - val_loss: 5.1312e-05 - val_accuracy: 0.9343\n",
      "Epoch 317/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1075e-05 - accuracy: 0.9376 - val_loss: 5.1313e-05 - val_accuracy: 0.9347\n",
      "Epoch 318/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1066e-05 - accuracy: 0.9359 - val_loss: 5.1299e-05 - val_accuracy: 0.9347\n",
      "Epoch 319/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1057e-05 - accuracy: 0.9361 - val_loss: 5.1291e-05 - val_accuracy: 0.9360\n",
      "Epoch 320/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1051e-05 - accuracy: 0.9352 - val_loss: 5.1280e-05 - val_accuracy: 0.9350\n",
      "Epoch 321/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1044e-05 - accuracy: 0.9356 - val_loss: 5.1275e-05 - val_accuracy: 0.9360\n",
      "Epoch 322/500\n",
      "8000/8000 [==============================] - 0s 20us/step - loss: 5.1033e-05 - accuracy: 0.9371 - val_loss: 5.1266e-05 - val_accuracy: 0.9347\n",
      "Epoch 323/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.1027e-05 - accuracy: 0.9369 - val_loss: 5.1261e-05 - val_accuracy: 0.9353\n",
      "Epoch 324/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1024e-05 - accuracy: 0.9367 - val_loss: 5.1250e-05 - val_accuracy: 0.9353\n",
      "Epoch 325/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.1013e-05 - accuracy: 0.9373 - val_loss: 5.1246e-05 - val_accuracy: 0.9347\n",
      "Epoch 326/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.1006e-05 - accuracy: 0.9361 - val_loss: 5.1240e-05 - val_accuracy: 0.9357\n",
      "Epoch 327/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0999e-05 - accuracy: 0.9370 - val_loss: 5.1223e-05 - val_accuracy: 0.9360\n",
      "Epoch 328/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0993e-05 - accuracy: 0.9375 - val_loss: 5.1220e-05 - val_accuracy: 0.9350\n",
      "Epoch 329/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0984e-05 - accuracy: 0.9366 - val_loss: 5.1213e-05 - val_accuracy: 0.9343\n",
      "Epoch 330/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0976e-05 - accuracy: 0.9362 - val_loss: 5.1204e-05 - val_accuracy: 0.9377\n",
      "Epoch 331/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0970e-05 - accuracy: 0.9364 - val_loss: 5.1205e-05 - val_accuracy: 0.9360\n",
      "Epoch 332/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0964e-05 - accuracy: 0.9367 - val_loss: 5.1191e-05 - val_accuracy: 0.9380\n",
      "Epoch 333/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0958e-05 - accuracy: 0.9367 - val_loss: 5.1182e-05 - val_accuracy: 0.9343\n",
      "Epoch 334/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0948e-05 - accuracy: 0.9370 - val_loss: 5.1179e-05 - val_accuracy: 0.9353\n",
      "Epoch 335/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0939e-05 - accuracy: 0.9371 - val_loss: 5.1166e-05 - val_accuracy: 0.9353\n",
      "Epoch 336/500\n",
      "8000/8000 [==============================] - 0s 19us/step - loss: 5.0933e-05 - accuracy: 0.9379 - val_loss: 5.1162e-05 - val_accuracy: 0.9363\n",
      "Epoch 337/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0926e-05 - accuracy: 0.9369 - val_loss: 5.1155e-05 - val_accuracy: 0.9350\n",
      "Epoch 338/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0917e-05 - accuracy: 0.9370 - val_loss: 5.1143e-05 - val_accuracy: 0.9360\n",
      "Epoch 339/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0910e-05 - accuracy: 0.9379 - val_loss: 5.1140e-05 - val_accuracy: 0.9363\n",
      "Epoch 340/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.0904e-05 - accuracy: 0.9367 - val_loss: 5.1126e-05 - val_accuracy: 0.9353\n",
      "Epoch 341/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0895e-05 - accuracy: 0.9362 - val_loss: 5.1126e-05 - val_accuracy: 0.9353\n",
      "Epoch 342/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0889e-05 - accuracy: 0.9370 - val_loss: 5.1118e-05 - val_accuracy: 0.9370\n",
      "Epoch 343/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0882e-05 - accuracy: 0.9371 - val_loss: 5.1111e-05 - val_accuracy: 0.9360\n",
      "Epoch 344/500\n",
      "8000/8000 [==============================] - 0s 19us/step - loss: 5.0876e-05 - accuracy: 0.9373 - val_loss: 5.1100e-05 - val_accuracy: 0.9350\n",
      "Epoch 345/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.0868e-05 - accuracy: 0.9364 - val_loss: 5.1094e-05 - val_accuracy: 0.9347\n",
      "Epoch 346/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0863e-05 - accuracy: 0.9375 - val_loss: 5.1088e-05 - val_accuracy: 0.9353\n",
      "Epoch 347/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0853e-05 - accuracy: 0.9376 - val_loss: 5.1080e-05 - val_accuracy: 0.9360\n",
      "Epoch 348/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.0849e-05 - accuracy: 0.9376 - val_loss: 5.1075e-05 - val_accuracy: 0.9360\n",
      "Epoch 349/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0843e-05 - accuracy: 0.9375 - val_loss: 5.1066e-05 - val_accuracy: 0.9360\n",
      "Epoch 350/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0836e-05 - accuracy: 0.9374 - val_loss: 5.1060e-05 - val_accuracy: 0.9367\n",
      "Epoch 351/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0829e-05 - accuracy: 0.9384 - val_loss: 5.1053e-05 - val_accuracy: 0.9360\n",
      "Epoch 352/500\n",
      "8000/8000 [==============================] - 0s 19us/step - loss: 5.0821e-05 - accuracy: 0.9376 - val_loss: 5.1049e-05 - val_accuracy: 0.9363\n",
      "Epoch 353/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.0814e-05 - accuracy: 0.9373 - val_loss: 5.1040e-05 - val_accuracy: 0.9353\n",
      "Epoch 354/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.0810e-05 - accuracy: 0.9380 - val_loss: 5.1030e-05 - val_accuracy: 0.9360\n",
      "Epoch 355/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.0800e-05 - accuracy: 0.9370 - val_loss: 5.1028e-05 - val_accuracy: 0.9353\n",
      "Epoch 356/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0800e-05 - accuracy: 0.9379 - val_loss: 5.1017e-05 - val_accuracy: 0.9367\n",
      "Epoch 357/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0793e-05 - accuracy: 0.9384 - val_loss: 5.1014e-05 - val_accuracy: 0.9360\n",
      "Epoch 358/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0783e-05 - accuracy: 0.9389 - val_loss: 5.1017e-05 - val_accuracy: 0.9363\n",
      "Epoch 359/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0775e-05 - accuracy: 0.9376 - val_loss: 5.0998e-05 - val_accuracy: 0.9360\n",
      "Epoch 360/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0770e-05 - accuracy: 0.9376 - val_loss: 5.0992e-05 - val_accuracy: 0.9347\n",
      "Epoch 361/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.0761e-05 - accuracy: 0.9376 - val_loss: 5.0982e-05 - val_accuracy: 0.9370\n",
      "Epoch 362/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0757e-05 - accuracy: 0.9373 - val_loss: 5.0975e-05 - val_accuracy: 0.9353\n",
      "Epoch 363/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0748e-05 - accuracy: 0.9384 - val_loss: 5.0975e-05 - val_accuracy: 0.9353\n",
      "Epoch 364/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.0744e-05 - accuracy: 0.9379 - val_loss: 5.0964e-05 - val_accuracy: 0.9367\n",
      "Epoch 365/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0738e-05 - accuracy: 0.9389 - val_loss: 5.0956e-05 - val_accuracy: 0.9377\n",
      "Epoch 366/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0730e-05 - accuracy: 0.9381 - val_loss: 5.0955e-05 - val_accuracy: 0.9373\n",
      "Epoch 367/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0726e-05 - accuracy: 0.9383 - val_loss: 5.0949e-05 - val_accuracy: 0.9373\n",
      "Epoch 368/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0717e-05 - accuracy: 0.9377 - val_loss: 5.0942e-05 - val_accuracy: 0.9367\n",
      "Epoch 369/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0711e-05 - accuracy: 0.9385 - val_loss: 5.0928e-05 - val_accuracy: 0.9357\n",
      "Epoch 370/500\n",
      "8000/8000 [==============================] - 0s 21us/step - loss: 5.0705e-05 - accuracy: 0.9384 - val_loss: 5.0928e-05 - val_accuracy: 0.9370\n",
      "Epoch 371/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0699e-05 - accuracy: 0.9379 - val_loss: 5.0915e-05 - val_accuracy: 0.9360\n",
      "Epoch 372/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0692e-05 - accuracy: 0.9377 - val_loss: 5.0912e-05 - val_accuracy: 0.9360\n",
      "Epoch 373/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0685e-05 - accuracy: 0.9391 - val_loss: 5.0903e-05 - val_accuracy: 0.9380\n",
      "Epoch 374/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0679e-05 - accuracy: 0.9384 - val_loss: 5.0901e-05 - val_accuracy: 0.9373\n",
      "Epoch 375/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0679e-05 - accuracy: 0.9394 - val_loss: 5.0898e-05 - val_accuracy: 0.9363\n",
      "Epoch 376/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0672e-05 - accuracy: 0.9388 - val_loss: 5.0885e-05 - val_accuracy: 0.9367\n",
      "Epoch 377/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0666e-05 - accuracy: 0.9391 - val_loss: 5.0884e-05 - val_accuracy: 0.9380\n",
      "Epoch 378/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0657e-05 - accuracy: 0.9395 - val_loss: 5.0872e-05 - val_accuracy: 0.9360\n",
      "Epoch 379/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0649e-05 - accuracy: 0.9384 - val_loss: 5.0872e-05 - val_accuracy: 0.9350\n",
      "Epoch 380/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0644e-05 - accuracy: 0.9383 - val_loss: 5.0859e-05 - val_accuracy: 0.9383\n",
      "Epoch 381/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0637e-05 - accuracy: 0.9392 - val_loss: 5.0854e-05 - val_accuracy: 0.9377\n",
      "Epoch 382/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0632e-05 - accuracy: 0.9384 - val_loss: 5.0848e-05 - val_accuracy: 0.9380\n",
      "Epoch 383/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0625e-05 - accuracy: 0.9385 - val_loss: 5.0848e-05 - val_accuracy: 0.9360\n",
      "Epoch 384/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0619e-05 - accuracy: 0.9391 - val_loss: 5.0839e-05 - val_accuracy: 0.9363\n",
      "Epoch 385/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0614e-05 - accuracy: 0.9384 - val_loss: 5.0829e-05 - val_accuracy: 0.9380\n",
      "Epoch 386/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0607e-05 - accuracy: 0.9389 - val_loss: 5.0822e-05 - val_accuracy: 0.9370\n",
      "Epoch 387/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0600e-05 - accuracy: 0.9392 - val_loss: 5.0821e-05 - val_accuracy: 0.9383\n",
      "Epoch 388/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0594e-05 - accuracy: 0.9398 - val_loss: 5.0809e-05 - val_accuracy: 0.9370\n",
      "Epoch 389/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.0590e-05 - accuracy: 0.9385 - val_loss: 5.0805e-05 - val_accuracy: 0.9370\n",
      "Epoch 390/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0585e-05 - accuracy: 0.9391 - val_loss: 5.0803e-05 - val_accuracy: 0.9370\n",
      "Epoch 391/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0579e-05 - accuracy: 0.9398 - val_loss: 5.0792e-05 - val_accuracy: 0.9363\n",
      "Epoch 392/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0574e-05 - accuracy: 0.9390 - val_loss: 5.0796e-05 - val_accuracy: 0.9377\n",
      "Epoch 393/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.0565e-05 - accuracy: 0.9394 - val_loss: 5.0783e-05 - val_accuracy: 0.9373\n",
      "Epoch 394/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0562e-05 - accuracy: 0.9388 - val_loss: 5.0779e-05 - val_accuracy: 0.9367\n",
      "Epoch 395/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0556e-05 - accuracy: 0.9384 - val_loss: 5.0770e-05 - val_accuracy: 0.9370\n",
      "Epoch 396/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0551e-05 - accuracy: 0.9392 - val_loss: 5.0765e-05 - val_accuracy: 0.9377\n",
      "Epoch 397/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0546e-05 - accuracy: 0.9396 - val_loss: 5.0761e-05 - val_accuracy: 0.9373\n",
      "Epoch 398/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0539e-05 - accuracy: 0.9400 - val_loss: 5.0755e-05 - val_accuracy: 0.9383\n",
      "Epoch 399/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0537e-05 - accuracy: 0.9388 - val_loss: 5.0751e-05 - val_accuracy: 0.9367\n",
      "Epoch 400/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0530e-05 - accuracy: 0.9400 - val_loss: 5.0743e-05 - val_accuracy: 0.9380\n",
      "Epoch 401/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0524e-05 - accuracy: 0.9399 - val_loss: 5.0733e-05 - val_accuracy: 0.9377\n",
      "Epoch 402/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0516e-05 - accuracy: 0.9401 - val_loss: 5.0736e-05 - val_accuracy: 0.9373\n",
      "Epoch 403/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0510e-05 - accuracy: 0.9392 - val_loss: 5.0714e-05 - val_accuracy: 0.9380\n",
      "Epoch 404/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0506e-05 - accuracy: 0.9398 - val_loss: 5.0729e-05 - val_accuracy: 0.9377\n",
      "Epoch 405/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0499e-05 - accuracy: 0.9399 - val_loss: 5.0709e-05 - val_accuracy: 0.9387\n",
      "Epoch 406/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0496e-05 - accuracy: 0.9389 - val_loss: 5.0712e-05 - val_accuracy: 0.9383\n",
      "Epoch 407/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0493e-05 - accuracy: 0.9406 - val_loss: 5.0698e-05 - val_accuracy: 0.9387\n",
      "Epoch 408/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0484e-05 - accuracy: 0.9400 - val_loss: 5.0702e-05 - val_accuracy: 0.9367\n",
      "Epoch 409/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0478e-05 - accuracy: 0.9389 - val_loss: 5.0690e-05 - val_accuracy: 0.9393\n",
      "Epoch 410/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0477e-05 - accuracy: 0.9404 - val_loss: 5.0688e-05 - val_accuracy: 0.9367\n",
      "Epoch 411/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0468e-05 - accuracy: 0.9399 - val_loss: 5.0676e-05 - val_accuracy: 0.9373\n",
      "Epoch 412/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0462e-05 - accuracy: 0.9404 - val_loss: 5.0677e-05 - val_accuracy: 0.9393\n",
      "Epoch 413/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0460e-05 - accuracy: 0.9391 - val_loss: 5.0670e-05 - val_accuracy: 0.9360\n",
      "Epoch 414/500\n",
      "8000/8000 [==============================] - 0s 19us/step - loss: 5.0452e-05 - accuracy: 0.9394 - val_loss: 5.0668e-05 - val_accuracy: 0.9380\n",
      "Epoch 415/500\n",
      "8000/8000 [==============================] - 0s 21us/step - loss: 5.0447e-05 - accuracy: 0.9402 - val_loss: 5.0655e-05 - val_accuracy: 0.9397\n",
      "Epoch 416/500\n",
      "8000/8000 [==============================] - 0s 25us/step - loss: 5.0441e-05 - accuracy: 0.9396 - val_loss: 5.0650e-05 - val_accuracy: 0.9377\n",
      "Epoch 417/500\n",
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.0437e-05 - accuracy: 0.9396 - val_loss: 5.0646e-05 - val_accuracy: 0.9387\n",
      "Epoch 418/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0432e-05 - accuracy: 0.9398 - val_loss: 5.0638e-05 - val_accuracy: 0.9370\n",
      "Epoch 419/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 18us/step - loss: 5.0421e-05 - accuracy: 0.9401 - val_loss: 5.0637e-05 - val_accuracy: 0.9387\n",
      "Epoch 420/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0421e-05 - accuracy: 0.9398 - val_loss: 5.0633e-05 - val_accuracy: 0.9377\n",
      "Epoch 421/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.0417e-05 - accuracy: 0.9404 - val_loss: 5.0626e-05 - val_accuracy: 0.9373\n",
      "Epoch 422/500\n",
      "8000/8000 [==============================] - 0s 19us/step - loss: 5.0414e-05 - accuracy: 0.9398 - val_loss: 5.0618e-05 - val_accuracy: 0.9367\n",
      "Epoch 423/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0407e-05 - accuracy: 0.9391 - val_loss: 5.0613e-05 - val_accuracy: 0.9377\n",
      "Epoch 424/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.0401e-05 - accuracy: 0.9404 - val_loss: 5.0607e-05 - val_accuracy: 0.9383\n",
      "Epoch 425/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.0392e-05 - accuracy: 0.9400 - val_loss: 5.0606e-05 - val_accuracy: 0.9367\n",
      "Epoch 426/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.0389e-05 - accuracy: 0.9394 - val_loss: 5.0593e-05 - val_accuracy: 0.9393\n",
      "Epoch 427/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0385e-05 - accuracy: 0.9404 - val_loss: 5.0595e-05 - val_accuracy: 0.9390\n",
      "Epoch 428/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0380e-05 - accuracy: 0.9401 - val_loss: 5.0591e-05 - val_accuracy: 0.9373\n",
      "Epoch 429/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0376e-05 - accuracy: 0.9404 - val_loss: 5.0578e-05 - val_accuracy: 0.9387\n",
      "Epoch 430/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0370e-05 - accuracy: 0.9405 - val_loss: 5.0578e-05 - val_accuracy: 0.9373\n",
      "Epoch 431/500\n",
      "8000/8000 [==============================] - 0s 17us/step - loss: 5.0363e-05 - accuracy: 0.9402 - val_loss: 5.0572e-05 - val_accuracy: 0.9367\n",
      "Epoch 432/500\n",
      "8000/8000 [==============================] - 0s 15us/step - loss: 5.0356e-05 - accuracy: 0.9415 - val_loss: 5.0569e-05 - val_accuracy: 0.9383\n",
      "Epoch 433/500\n",
      "8000/8000 [==============================] - 0s 13us/step - loss: 5.0355e-05 - accuracy: 0.9399 - val_loss: 5.0558e-05 - val_accuracy: 0.9397\n",
      "Epoch 434/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0351e-05 - accuracy: 0.9398 - val_loss: 5.0549e-05 - val_accuracy: 0.9363\n",
      "Epoch 435/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0348e-05 - accuracy: 0.9401 - val_loss: 5.0555e-05 - val_accuracy: 0.9403\n",
      "Epoch 436/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0339e-05 - accuracy: 0.9402 - val_loss: 5.0546e-05 - val_accuracy: 0.9383\n",
      "Epoch 437/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0335e-05 - accuracy: 0.9415 - val_loss: 5.0542e-05 - val_accuracy: 0.9407\n",
      "Epoch 438/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0329e-05 - accuracy: 0.9401 - val_loss: 5.0538e-05 - val_accuracy: 0.9367\n",
      "Epoch 439/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0324e-05 - accuracy: 0.9401 - val_loss: 5.0526e-05 - val_accuracy: 0.9397\n",
      "Epoch 440/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0317e-05 - accuracy: 0.9402 - val_loss: 5.0526e-05 - val_accuracy: 0.9387\n",
      "Epoch 441/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0315e-05 - accuracy: 0.9399 - val_loss: 5.0521e-05 - val_accuracy: 0.9390\n",
      "Epoch 442/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0312e-05 - accuracy: 0.9401 - val_loss: 5.0513e-05 - val_accuracy: 0.9393\n",
      "Epoch 443/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0311e-05 - accuracy: 0.9406 - val_loss: 5.0513e-05 - val_accuracy: 0.9360\n",
      "Epoch 444/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0300e-05 - accuracy: 0.9410 - val_loss: 5.0508e-05 - val_accuracy: 0.9397\n",
      "Epoch 445/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0298e-05 - accuracy: 0.9409 - val_loss: 5.0497e-05 - val_accuracy: 0.9387\n",
      "Epoch 446/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0289e-05 - accuracy: 0.9409 - val_loss: 5.0497e-05 - val_accuracy: 0.9397\n",
      "Epoch 447/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0291e-05 - accuracy: 0.9404 - val_loss: 5.0488e-05 - val_accuracy: 0.9377\n",
      "Epoch 448/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0286e-05 - accuracy: 0.9416 - val_loss: 5.0488e-05 - val_accuracy: 0.9383\n",
      "Epoch 449/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0288e-05 - accuracy: 0.9399 - val_loss: 5.0479e-05 - val_accuracy: 0.9397\n",
      "Epoch 450/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0271e-05 - accuracy: 0.9406 - val_loss: 5.0474e-05 - val_accuracy: 0.9373\n",
      "Epoch 451/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0270e-05 - accuracy: 0.9406 - val_loss: 5.0477e-05 - val_accuracy: 0.9390\n",
      "Epoch 452/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.0268e-05 - accuracy: 0.9405 - val_loss: 5.0467e-05 - val_accuracy: 0.9397\n",
      "Epoch 453/500\n",
      "8000/8000 [==============================] - 0s 21us/step - loss: 5.0259e-05 - accuracy: 0.9398 - val_loss: 5.0462e-05 - val_accuracy: 0.9380\n",
      "Epoch 454/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0255e-05 - accuracy: 0.9406 - val_loss: 5.0459e-05 - val_accuracy: 0.9380\n",
      "Epoch 455/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0254e-05 - accuracy: 0.9401 - val_loss: 5.0451e-05 - val_accuracy: 0.9377\n",
      "Epoch 456/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0251e-05 - accuracy: 0.9415 - val_loss: 5.0446e-05 - val_accuracy: 0.9380\n",
      "Epoch 457/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0245e-05 - accuracy: 0.9417 - val_loss: 5.0447e-05 - val_accuracy: 0.9390\n",
      "Epoch 458/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0239e-05 - accuracy: 0.9406 - val_loss: 5.0441e-05 - val_accuracy: 0.9397\n",
      "Epoch 459/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0240e-05 - accuracy: 0.9411 - val_loss: 5.0439e-05 - val_accuracy: 0.9383\n",
      "Epoch 460/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0229e-05 - accuracy: 0.9399 - val_loss: 5.0422e-05 - val_accuracy: 0.9383\n",
      "Epoch 461/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0226e-05 - accuracy: 0.9420 - val_loss: 5.0425e-05 - val_accuracy: 0.9387\n",
      "Epoch 462/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0219e-05 - accuracy: 0.9411 - val_loss: 5.0419e-05 - val_accuracy: 0.9373\n",
      "Epoch 463/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0210e-05 - accuracy: 0.9406 - val_loss: 5.0412e-05 - val_accuracy: 0.9407\n",
      "Epoch 464/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0207e-05 - accuracy: 0.9408 - val_loss: 5.0411e-05 - val_accuracy: 0.9383\n",
      "Epoch 465/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.0205e-05 - accuracy: 0.9409 - val_loss: 5.0398e-05 - val_accuracy: 0.9397\n",
      "Epoch 466/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0200e-05 - accuracy: 0.9415 - val_loss: 5.0398e-05 - val_accuracy: 0.9410\n",
      "Epoch 467/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0195e-05 - accuracy: 0.9404 - val_loss: 5.0390e-05 - val_accuracy: 0.9390\n",
      "Epoch 468/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0192e-05 - accuracy: 0.9411 - val_loss: 5.0396e-05 - val_accuracy: 0.9387\n",
      "Epoch 469/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0186e-05 - accuracy: 0.9406 - val_loss: 5.0384e-05 - val_accuracy: 0.9373\n",
      "Epoch 470/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0183e-05 - accuracy: 0.9401 - val_loss: 5.0381e-05 - val_accuracy: 0.9400\n",
      "Epoch 471/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0182e-05 - accuracy: 0.9419 - val_loss: 5.0375e-05 - val_accuracy: 0.9403\n",
      "Epoch 472/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0176e-05 - accuracy: 0.9414 - val_loss: 5.0376e-05 - val_accuracy: 0.9403\n",
      "Epoch 473/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0174e-05 - accuracy: 0.9415 - val_loss: 5.0365e-05 - val_accuracy: 0.9403\n",
      "Epoch 474/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0172e-05 - accuracy: 0.9420 - val_loss: 5.0364e-05 - val_accuracy: 0.9397\n",
      "Epoch 475/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0163e-05 - accuracy: 0.9411 - val_loss: 5.0360e-05 - val_accuracy: 0.9380\n",
      "Epoch 476/500\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 5.0162e-05 - accuracy: 0.9415 - val_loss: 5.0348e-05 - val_accuracy: 0.9390\n",
      "Epoch 477/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0162e-05 - accuracy: 0.9415 - val_loss: 5.0360e-05 - val_accuracy: 0.9393\n",
      "Epoch 478/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0154e-05 - accuracy: 0.9405 - val_loss: 5.0355e-05 - val_accuracy: 0.9387\n",
      "Epoch 479/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0149e-05 - accuracy: 0.9410 - val_loss: 5.0343e-05 - val_accuracy: 0.9383\n",
      "Epoch 480/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0143e-05 - accuracy: 0.9410 - val_loss: 5.0344e-05 - val_accuracy: 0.9407\n",
      "Epoch 481/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0140e-05 - accuracy: 0.9411 - val_loss: 5.0329e-05 - val_accuracy: 0.9393\n",
      "Epoch 482/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0133e-05 - accuracy: 0.9401 - val_loss: 5.0320e-05 - val_accuracy: 0.9403\n",
      "Epoch 483/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0126e-05 - accuracy: 0.9413 - val_loss: 5.0324e-05 - val_accuracy: 0.9410\n",
      "Epoch 484/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0125e-05 - accuracy: 0.9411 - val_loss: 5.0323e-05 - val_accuracy: 0.9383\n",
      "Epoch 485/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0117e-05 - accuracy: 0.9417 - val_loss: 5.0310e-05 - val_accuracy: 0.9393\n",
      "Epoch 486/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0119e-05 - accuracy: 0.9425 - val_loss: 5.0304e-05 - val_accuracy: 0.9383\n",
      "Epoch 487/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0114e-05 - accuracy: 0.9411 - val_loss: 5.0312e-05 - val_accuracy: 0.9413\n",
      "Epoch 488/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0112e-05 - accuracy: 0.9421 - val_loss: 5.0298e-05 - val_accuracy: 0.9380\n",
      "Epoch 489/500\n",
      "8000/8000 [==============================] - 0s 16us/step - loss: 5.0105e-05 - accuracy: 0.9401 - val_loss: 5.0304e-05 - val_accuracy: 0.9390\n",
      "Epoch 490/500\n",
      "8000/8000 [==============================] - 0s 14us/step - loss: 5.0099e-05 - accuracy: 0.9427 - val_loss: 5.0288e-05 - val_accuracy: 0.9403\n",
      "Epoch 491/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0099e-05 - accuracy: 0.9411 - val_loss: 5.0290e-05 - val_accuracy: 0.9383\n",
      "Epoch 492/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0097e-05 - accuracy: 0.9398 - val_loss: 5.0290e-05 - val_accuracy: 0.9383\n",
      "Epoch 493/500\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 5.0092e-05 - accuracy: 0.9421 - val_loss: 5.0280e-05 - val_accuracy: 0.9387\n",
      "Epoch 494/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0087e-05 - accuracy: 0.9402 - val_loss: 5.0280e-05 - val_accuracy: 0.9390\n",
      "Epoch 495/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0089e-05 - accuracy: 0.9421 - val_loss: 5.0279e-05 - val_accuracy: 0.9420\n",
      "Epoch 496/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0076e-05 - accuracy: 0.9416 - val_loss: 5.0258e-05 - val_accuracy: 0.9403\n",
      "Epoch 497/500\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 5.0071e-05 - accuracy: 0.9419 - val_loss: 5.0271e-05 - val_accuracy: 0.9397\n",
      "Epoch 498/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0071e-05 - accuracy: 0.9399 - val_loss: 5.0255e-05 - val_accuracy: 0.9410\n",
      "Epoch 499/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0070e-05 - accuracy: 0.9408 - val_loss: 5.0258e-05 - val_accuracy: 0.9393\n",
      "Epoch 500/500\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 5.0061e-05 - accuracy: 0.9417 - val_loss: 5.0249e-05 - val_accuracy: 0.9397\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Activation, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "model = Sequential()\n",
    "keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "keras.optimizers.Adamax(learning_rate=0.9, beta_1=0.999, beta_2=0.999)\n",
    "model.add(Dense(units =32, kernel_initializer = 'uniform', activation = 'tanh', input_dim =20))\n",
    "model.add(Dense(units =200, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model.compile(optimizer = 'Adamax', loss = 'mse', metrics = ['accuracy'])\n",
    "history =model.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size=2000, epochs=1000,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Weights Vector of NN1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4620\n"
     ]
    }
   ],
   "source": [
    "first_layer_weights =model.layers[0].get_weights()[0] \n",
    "first=first_layer_weights.flatten()\n",
    "first_layer_biases  = model.layers[0].get_weights()[1]\n",
    "first_layer=np.concatenate((first,first_layer_biases),axis=0)\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "second=second_layer_weights.flatten()\n",
    "second_layer_biases  = model.layers[1].get_weights()[1]\n",
    "second_layer=np.concatenate((second,second_layer_biases),axis=0)\n",
    "weights=np.concatenate((first_layer,second_layer),axis=0)\n",
    "print (len(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Make Predictions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Accuracy Representation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.grid(True,which=\"both\", linestyle='--')\n",
    "plt.ylabel('Accuracy') \n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Loss Representation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.grid(True,which=\"both\", linestyle='--')\n",
    "plt.ylabel('Loss') \n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#006400\"> Mean-Squared-Error</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squred Error: -23.418768685707985\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NMSE_Units=[]\n",
    "NMSE=np.zeros([5000,1])\n",
    "recievehh=np.zeros([5000,10],dtype=complex)\n",
    "Y_gdr=y_pred[:,:100]\n",
    "Y_gdi=1j*y_pred[:,100:]\n",
    "Y_gd=Y_gdr+Y_gdi\n",
    "Shr=X_train[:,:10]\n",
    "Shi=1j*X_train[:,10:20]\n",
    "SSh=Shr+Shi\n",
    "for i in range(5000):\n",
    "    val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "    coeff_IBO_m1dB=val_IBO_m1dB*np.sqrt((1/np.var(Y_gd[i])))*np.sqrt(10**(-IBO/10))\n",
    "    vin2=coeff_IBO_m1dB*Y_gd[i]\n",
    "    vout2=hpa_sspa_modif_rapp(vin2,Vsat,p,q,G,A,B)\n",
    "    Y_gd_amp = vout2/coeff_IBO_m1dB\n",
    "    recieveh=(H.dot(Y_gd_amp)).reshape((10))\n",
    "    recievehh[i]=recieveh\n",
    "    NMSE[i]=(np.mean(np.abs(ZZ[i]-recieveh)**2)/np.mean(np.abs(ZZ[i])**2))\n",
    "    NMSEdb=10*np.log10(np.mean(NMSE[i]))\n",
    "recievehhh=recievehh.flatten()\n",
    "realr=np.real(recievehhh)\n",
    "imagr=np.imag(recievehhh)\n",
    "plt.scatter(realr,imagr)    \n",
    "print('Mean Squred Error:', NMSEdb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squred Error: -23.921055989090263\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NMSE=np.zeros([1000,1])\n",
    "recievehh=np.zeros([1000,10],dtype=complex)\n",
    "Y_gdr=y_pred_test[:,:100]\n",
    "Y_gdr=y_pred_test[:,:100]\n",
    "Y_gdi=1j*y_pred_test[:,100:]\n",
    "Y_gd=Y_gdr+Y_gdi\n",
    "Shr=X_test[:,:10]\n",
    "Shi=1j*X_test[:,10:20]\n",
    "SSh=Shr+Shi\n",
    "for i in range(1000):\n",
    "    val_IBO_m1dB=((1/np.sqrt(10**-0.1))**(2*p)-1)**(1/(2*p))*Vsat/(G)\n",
    "    coeff_IBO_m1dB=val_IBO_m1dB*np.sqrt((1/np.var(Y_gd[i])))*np.sqrt(10**(-IBO/10))\n",
    "    vin2=coeff_IBO_m1dB*Y_gd[i]\n",
    "    vout2=hpa_sspa_modif_rapp(vin2,Vsat,p,q,G,A,B)\n",
    "    Y_gd_amp = vout2/coeff_IBO_m1dB\n",
    "    recieveh=(H.dot(Y_gd_amp)).reshape((10))\n",
    "    recievehh[i]=recieveh\n",
    "    NMSE[i]=(np.mean(np.abs(SSh[i]-recieveh)**2)/np.mean(np.abs(SSh[i])**2))\n",
    "    NMSEdb=10*np.log10(np.mean(NMSE[i]))\n",
    "recievehhh=recievehh.flatten()\n",
    "realr=np.real(recievehhh)\n",
    "imagr=np.imag(recievehhh)\n",
    "plt.scatter(realr,imagr)    \n",
    "print('Mean Squred Error:', NMSEdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
